{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11674976,"sourceType":"datasetVersion","datasetId":7327319},{"sourceId":11709997,"sourceType":"datasetVersion","datasetId":7350177}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install --no-deps seqeval[gpu]\n!python -m spacy download en_core_web_lg\n!pip install pytorch-pretrained-bert\n!pip install PyMuPDF\nimport locale\nimport nltk\nnltk.download('punkt')\nnltk.download('stopwords')\nnltk.download('averaged_perceptron_tagger')\n\ndef getpreferredencoding(do_setlocale = True):\n    return \"UTF-8\"\nlocale.getpreferredencoding = getpreferredencoding","metadata":{"id":"UNCciV-vQ5cL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683800119122,"user_tz":-480,"elapsed":61942,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"a8cfd491-ace9-4ea3-f277-293233d0ed0d","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:56:50.579292Z","iopub.execute_input":"2025-05-06T23:56:50.579729Z","iopub.status.idle":"2025-05-06T23:59:02.396838Z","shell.execute_reply.started":"2025-05-06T23:56:50.579708Z","shell.execute_reply":"2025-05-06T23:59:02.396078Z"}},"outputs":[{"name":"stdout","text":"Collecting seqeval[gpu]\n  Downloading seqeval-1.2.2.tar.gz (43 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\nBuilding wheels for collected packages: seqeval\n  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=40aadbee4930bd7c8090da2f34c694f55bbabc83872bae3c73a4cfd0934d27f8\n  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\nSuccessfully built seqeval\nInstalling collected packages: seqeval\nSuccessfully installed seqeval-1.2.2\nCollecting en-core-web-lg==3.7.1\n  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_lg-3.7.1/en_core_web_lg-3.7.1-py3-none-any.whl (587.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m587.7/587.7 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.11/dist-packages (from en-core-web-lg==3.7.1) (3.7.5)\nRequirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.12)\nRequirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.5)\nRequirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.0.12)\nRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.11)\nRequirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.9)\nRequirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.2.5)\nRequirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.1.3)\nRequirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.5.1)\nRequirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.0.10)\nRequirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.1)\nRequirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.15.1)\nRequirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.67.1)\nRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.32.3)\nRequirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.11.3)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.1.6)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (75.1.0)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (24.2)\nRequirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.5.0)\nRequirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.11/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.26.4)\nRequirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.11/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.4.1)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.33.1)\nRequirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (4.13.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2025.1.31)\nRequirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.7.11)\nRequirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.11/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.5)\nRequirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (8.1.8)\nRequirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.5.4)\nRequirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (14.0.0)\nRequirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.20.0)\nRequirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.11/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (7.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.2)\nRequirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.1)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2.19.1)\nRequirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.17.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.19.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (2024.2.0)\nRequirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-lg==3.7.1) (0.1.2)\nInstalling collected packages: en-core-web-lg\nSuccessfully installed en-core-web-lg-3.7.1\n\u001b[38;5;2m✔ Download and installation successful\u001b[0m\nYou can now load the package via spacy.load('en_core_web_lg')\n\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\nIf you are in a Jupyter or Colab notebook, you may need to restart Python in\norder to load all the package's dependencies. You can do this by selecting the\n'Restart kernel' or 'Restart runtime' option.\nCollecting pytorch-pretrained-bert\n  Downloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl.metadata (86 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.5.1+cu124)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (1.26.4)\nRequirement already satisfied: boto3 in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (1.37.29)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (4.67.1)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from pytorch-pretrained-bert) (2024.11.6)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (4.13.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12==12.4.5.8 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=0.4.1->pytorch-pretrained-bert)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (3.1.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=0.4.1->pytorch-pretrained-bert) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=0.4.1->pytorch-pretrained-bert) (1.3.0)\nRequirement already satisfied: botocore<1.38.0,>=1.37.29 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.37.29)\nRequirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (1.0.1)\nRequirement already satisfied: s3transfer<0.12.0,>=0.11.0 in /usr/local/lib/python3.11/dist-packages (from boto3->pytorch-pretrained-bert) (0.11.4)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->pytorch-pretrained-bert) (2.4.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->pytorch-pretrained-bert) (2025.1.31)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.11/dist-packages (from botocore<1.38.0,>=1.37.29->boto3->pytorch-pretrained-bert) (2.9.0.post0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=0.4.1->pytorch-pretrained-bert) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-pretrained-bert) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->pytorch-pretrained-bert) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->pytorch-pretrained-bert) (1.2.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->pytorch-pretrained-bert) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->pytorch-pretrained-bert) (2024.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.38.0,>=1.37.29->boto3->pytorch-pretrained-bert) (1.17.0)\nDownloading pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.8/123.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, pytorch-pretrained-bert\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.8.93\n    Uninstalling nvidia-nvjitlink-cu12-12.8.93:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.8.93\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.9.90\n    Uninstalling nvidia-curand-cu12-10.3.9.90:\n      Successfully uninstalled nvidia-curand-cu12-10.3.9.90\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.3.3.83\n    Uninstalling nvidia-cufft-cu12-11.3.3.83:\n      Successfully uninstalled nvidia-cufft-cu12-11.3.3.83\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.8.4.1\n    Uninstalling nvidia-cublas-cu12-12.8.4.1:\n      Successfully uninstalled nvidia-cublas-cu12-12.8.4.1\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.8.93\n    Uninstalling nvidia-cusparse-cu12-12.5.8.93:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.8.93\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.3.90\n    Uninstalling nvidia-cusolver-cu12-11.7.3.90:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.3.90\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\npylibcugraph-cu12 24.12.0 requires pylibraft-cu12==24.12.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 24.12.0 requires rmm-cu12==24.12.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 pytorch-pretrained-bert-0.6.2\nCollecting PyMuPDF\n  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\nDownloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m79.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: PyMuPDF\nSuccessfully installed PyMuPDF-1.25.5\n","output_type":"stream"},{"name":"stderr","text":"[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n[nltk_data]   Package punkt is already up-to-date!\n[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n[nltk_data]   Package stopwords is already up-to-date!\n[nltk_data] Downloading package averaged_perceptron_tagger to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n[nltk_data]       date!\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"#Import Libraries","metadata":{"id":"IbFZRV5cLR5V"}},{"cell_type":"code","source":"import random\nrandom.seed(42)","metadata":{"id":"jqjtuNcFyXZ3","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:02.397666Z","iopub.execute_input":"2025-05-06T23:59:02.398061Z","iopub.status.idle":"2025-05-06T23:59:02.402147Z","shell.execute_reply.started":"2025-05-06T23:59:02.398026Z","shell.execute_reply":"2025-05-06T23:59:02.401309Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\n\nimport spacy\nfrom spacy.training import offsets_to_biluo_tags\nnlp=spacy.load('en_core_web_lg')\n\nfrom tqdm import trange\nimport torch\nimport torch.nn.functional as F \nfrom torch.optim import Adam\nfrom torch.utils.data import TensorDataset,DataLoader,RandomSampler,SequentialSampler\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom sklearn.model_selection import train_test_split\n\nfrom pytorch_pretrained_bert import BertTokenizer,BertConfig\nfrom pytorch_pretrained_bert import BertForTokenClassification,BertAdam\n\nfrom seqeval.metrics import classification_report,accuracy_score,f1_score\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#Text preprocessing tools\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords,wordnet\nfrom nltk import pos_tag\nfrom nltk.stem import WordNetLemmatizer\nimport fitz\n\n#Make each token predict result into softmax mode\nfrom scipy.special import softmax","metadata":{"id":"6K6Oi25wKsh-","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:02.403637Z","iopub.execute_input":"2025-05-06T23:59:02.403883Z","iopub.status.idle":"2025-05-06T23:59:27.801790Z","shell.execute_reply.started":"2025-05-06T23:59:02.403866Z","shell.execute_reply":"2025-05-06T23:59:27.801160Z"}},"outputs":[{"name":"stderr","text":"2025-05-06 23:59:11.046417: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1746575951.492121      31 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1746575951.614093      31 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"#Adding '\\n' to the default spacy tokenizer\nprefixes=[i+'\\\\n' for i in nlp.Defaults.prefixes]\nprefix_regex = spacy.util.compile_prefix_regex(prefixes)\nnlp.tokenizer.prefix_search = prefix_regex.search","metadata":{"id":"8C4XQW_lL4rH","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:27.802648Z","iopub.execute_input":"2025-05-06T23:59:27.803307Z","iopub.status.idle":"2025-05-06T23:59:27.911848Z","shell.execute_reply.started":"2025-05-06T23:59:27.803277Z","shell.execute_reply":"2025-05-06T23:59:27.911259Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#Personal custom tags dictionary\nentity_dict={\n    'Name':'NAME',\n    'College Name':'CLG',\n    'Degree':'DEG',\n    'Graduation Year':'GRADYEAR',\n    'Years of Experience': 'YOE',\n    'Companies worked at':'COMPANY',\n    'Designation':'DESIG',\n    'Skills':'SKILLS',\n    'Location':'LOC',\n    'Email Address':'EMAIL'\n}","metadata":{"id":"iYp1xhfyL6g8","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:27.912592Z","iopub.execute_input":"2025-05-06T23:59:27.912861Z","iopub.status.idle":"2025-05-06T23:59:28.599449Z","shell.execute_reply.started":"2025-05-06T23:59:27.912843Z","shell.execute_reply":"2025-05-06T23:59:28.598828Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"data=\"/kaggle/input/bertdata/data\"","metadata":{"id":"o56olqHn7VVR","executionInfo":{"status":"ok","timestamp":1683800288416,"user_tz":-480,"elapsed":85390,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"1113eb69-670b-4a3a-ea6f-416707e4259d","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.600230Z","iopub.execute_input":"2025-05-06T23:59:28.600501Z","iopub.status.idle":"2025-05-06T23:59:28.616410Z","shell.execute_reply.started":"2025-05-06T23:59:28.600482Z","shell.execute_reply":"2025-05-06T23:59:28.615813Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"#Load Data","metadata":{"id":"aXCWfoptLZNe"}},{"cell_type":"code","source":"import spacy\nfrom spacy.tokens import DocBin\nfrom tqdm import tqdm  \nimport json","metadata":{"id":"3c4xaEKCq2X6","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.617175Z","iopub.execute_input":"2025-05-06T23:59:28.617450Z","iopub.status.idle":"2025-05-06T23:59:28.630539Z","shell.execute_reply.started":"2025-05-06T23:59:28.617427Z","shell.execute_reply":"2025-05-06T23:59:28.630016Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"#Loading the dataset\ndata_file_address='/kaggle/input/bertdata/data/Resumes.json'\ndf=pd.read_json(data_file_address,lines=True)\ndf.head()","metadata":{"id":"k5q7CTMlL_SZ","colab":{"base_uri":"https://localhost:8080/","height":337},"executionInfo":{"status":"ok","timestamp":1683800299546,"user_tz":-480,"elapsed":1822,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"88893782-a32c-4329-bd6d-8f182931332f","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.631078Z","iopub.execute_input":"2025-05-06T23:59:28.631294Z","iopub.status.idle":"2025-05-06T23:59:28.786185Z","shell.execute_reply.started":"2025-05-06T23:59:28.631261Z","shell.execute_reply":"2025-05-06T23:59:28.785668Z"}},"outputs":[{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  extras  \n0  [{'label': ['Skills'], 'points': [{'start': 12...     NaN  \n1  [{'label': ['Email Address'], 'points': [{'sta...     NaN  \n2  [{'label': ['Skills'], 'points': [{'start': 37...     NaN  \n3  [{'label': ['Skills'], 'points': [{'start': 80...     NaN  \n4  [{'label': ['Degree'], 'points': [{'start': 20...     NaN  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n      <th>extras</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":8},{"cell_type":"code","source":"df.iloc[0]['content']","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":139},"id":"PsZf0RlqYF31","executionInfo":{"status":"ok","timestamp":1683633320376,"user_tz":-480,"elapsed":4,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"d1fee6ed-4543-46bd-89fc-2a09b528b614","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.788542Z","iopub.execute_input":"2025-05-06T23:59:28.789066Z","iopub.status.idle":"2025-05-06T23:59:28.793468Z","shell.execute_reply.started":"2025-05-06T23:59:28.789047Z","shell.execute_reply":"2025-05-06T23:59:28.792922Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"\"Abhishek Jha\\nApplication Development Associate - Accenture\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n\\n• To work for an organization which provides me the opportunity to improve my skills\\nand knowledge for my individual and company's growth in best possible ways.\\n\\nWilling to relocate to: Bangalore, Karnataka\\n\\nWORK EXPERIENCE\\n\\nApplication Development Associate\\n\\nAccenture -\\n\\nNovember 2017 to Present\\n\\nRole: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries\\nfor the Bot which will be triggered based on given input. Also, Training the bot for different possible\\nutterances (Both positive and negative), which will be given as\\ninput by the user.\\n\\nEDUCATION\\n\\nB.E in Information science and engineering\\n\\nB.v.b college of engineering and technology -  Hubli, Karnataka\\n\\nAugust 2013 to June 2017\\n\\n12th in Mathematics\\n\\nWoodbine modern school\\n\\nApril 2011 to March 2013\\n\\n10th\\n\\nKendriya Vidyalaya\\n\\nApril 2001 to March 2011\\n\\nSKILLS\\n\\nC (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Skills\\n\\nhttps://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player\""},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"df.iloc[0]['annotation']","metadata":{"id":"d-WShIKjxv1D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683633335627,"user_tz":-480,"elapsed":466,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"cf6bdd97-6902-419b-8504-8485ebc2eecc","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.794296Z","iopub.execute_input":"2025-05-06T23:59:28.794505Z","iopub.status.idle":"2025-05-06T23:59:28.859046Z","shell.execute_reply.started":"2025-05-06T23:59:28.794491Z","shell.execute_reply":"2025-05-06T23:59:28.858500Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[{'label': ['Skills'],\n  'points': [{'start': 1295,\n    'end': 1621,\n    'text': '\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player'}]},\n {'label': ['Skills'],\n  'points': [{'start': 993,\n    'end': 1153,\n    'text': 'C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)'}]},\n {'label': ['College Name'],\n  'points': [{'start': 939, 'end': 956, 'text': 'Kendriya Vidyalaya'}]},\n {'label': ['College Name'],\n  'points': [{'start': 883, 'end': 904, 'text': 'Woodbine modern school'}]},\n {'label': ['Graduation Year'],\n  'points': [{'start': 856, 'end': 860, 'text': '2017\\n'}]},\n {'label': ['College Name'],\n  'points': [{'start': 771,\n    'end': 813,\n    'text': 'B.v.b college of engineering and technology'}]},\n {'label': ['Designation'],\n  'points': [{'start': 727,\n    'end': 769,\n    'text': 'B.E in Information science and engineering\\n'}]},\n {'label': ['Companies worked at'],\n  'points': [{'start': 407, 'end': 415, 'text': 'Accenture'}]},\n {'label': ['Designation'],\n  'points': [{'start': 372,\n    'end': 404,\n    'text': 'Application Development Associate'}]},\n {'label': ['Email Address'],\n  'points': [{'start': 95,\n    'end': 145,\n    'text': 'Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n'}]},\n {'label': ['Location'],\n  'points': [{'start': 60, 'end': 68, 'text': 'Bengaluru'}]},\n {'label': ['Companies worked at'],\n  'points': [{'start': 49, 'end': 57, 'text': 'Accenture'}]},\n {'label': ['Designation'],\n  'points': [{'start': 13,\n    'end': 45,\n    'text': 'Application Development Associate'}]},\n {'label': ['Name'],\n  'points': [{'start': 0, 'end': 11, 'text': 'Abhishek Jha'}]}]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"print('Shape')\nprint('===============')\nprint(df.shape)\nprint('\\nCount')\nprint('===============')\nprint(df.count())\nprint('\\nIsnull Count')\nprint('===============')\nprint(df.isnull().sum())\nprint('\\nDescribe')\nprint('===============')\nprint(df.info())\nprint('\\nColumns')\nprint('===============')\nprint(df.columns)","metadata":{"id":"btVZhrQFo4h1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683633343965,"user_tz":-480,"elapsed":546,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"d958115f-a52b-4816-c59b-9cf48d897b1c","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.859951Z","iopub.execute_input":"2025-05-06T23:59:28.860182Z","iopub.status.idle":"2025-05-06T23:59:28.900593Z","shell.execute_reply.started":"2025-05-06T23:59:28.860166Z","shell.execute_reply":"2025-05-06T23:59:28.899945Z"}},"outputs":[{"name":"stdout","text":"Shape\n===============\n(220, 3)\n\nCount\n===============\ncontent       220\nannotation    220\nextras          0\ndtype: int64\n\nIsnull Count\n===============\ncontent         0\nannotation      0\nextras        220\ndtype: int64\n\nDescribe\n===============\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 220 entries, 0 to 219\nData columns (total 3 columns):\n #   Column      Non-Null Count  Dtype  \n---  ------      --------------  -----  \n 0   content     220 non-null    object \n 1   annotation  220 non-null    object \n 2   extras      0 non-null      float64\ndtypes: float64(1), object(2)\nmemory usage: 5.3+ KB\nNone\n\nColumns\n===============\nIndex(['content', 'annotation', 'extras'], dtype='object')\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"#Checking for unique values present in 'extras' column\ndf['extras'].unique()","metadata":{"id":"tCvjraCVMG2s","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683633350752,"user_tz":-480,"elapsed":990,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"a6bd3c86-8b3f-48ea-85fa-5670c83913b6","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.901336Z","iopub.execute_input":"2025-05-06T23:59:28.901596Z","iopub.status.idle":"2025-05-06T23:59:28.908118Z","shell.execute_reply.started":"2025-05-06T23:59:28.901572Z","shell.execute_reply":"2025-05-06T23:59:28.907630Z"}},"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([nan])"},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"#Since 'extras' column contains no information we can drop the column\ndf=df.drop(['extras'],axis=1)\ndf.head()","metadata":{"id":"wtNkEE8OMJJ8","colab":{"base_uri":"https://localhost:8080/","height":206},"executionInfo":{"status":"ok","timestamp":1683633353008,"user_tz":-480,"elapsed":4,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"c44a9b5a-8cf3-406b-f85c-a6e84122fd77","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.908754Z","iopub.execute_input":"2025-05-06T23:59:28.908917Z","iopub.status.idle":"2025-05-06T23:59:28.969290Z","shell.execute_reply.started":"2025-05-06T23:59:28.908906Z","shell.execute_reply":"2025-05-06T23:59:28.968676Z"}},"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  \n0  [{'label': ['Skills'], 'points': [{'start': 12...  \n1  [{'label': ['Email Address'], 'points': [{'sta...  \n2  [{'label': ['Skills'], 'points': [{'start': 37...  \n3  [{'label': ['Skills'], 'points': [{'start': 80...  \n4  [{'label': ['Degree'], 'points': [{'start': 20...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":13},{"cell_type":"markdown","source":"# Parser data\n- Parser data into document structure","metadata":{"id":"_v7xq298Roq9"}},{"cell_type":"code","source":"'''\nCase 1: if higher[0] <= lower[1], with the SAME ENT\n=====================================================\n  higher =  (0, 186, 'SKILLS')   -> Current new record\n  lower  =  (653, 656, 'SKILLS') -> Last merged list record\n  \n  higher[0] <= lower[1]     ,  0 <= 656\n  lower[2]   = higher[2]    ,  'SKILLS'\n  UB         = max (656,186),  -> UB=656\n  merged[-1] = previous record\n\n    Case 1.2: if higher[0] <= lower[1], DIFF ENT\n    =====================================================\n      higher =  (0, 186, 'NAME')   -> Current new record\n      lower  =  (653, 656, 'SKILLS') -> Last merged list record\n      \n      higher[0] <= lower[1]   , 0 <= 646\n      lower[2]  != higher[2]  , 'NAME'!='SKILLS'\n      lower[1]   > higher[1]  , 656 > 186 \n      merged[-1] =  previous record\n\nCase 1: if higher[0] >= lower[1], if current start value > lower end value\n===========================================================================\nAppend into entity\n  '''\n\ndef mergeIntervals(intervals):\n    #Sort based on the tuple start (start,end,label)\n    sorted_by_lower_bound = sorted(intervals, key=lambda tup: tup[0])\n    merged = []\n\n    for higher in sorted_by_lower_bound:\n        if not merged:\n            merged.append(higher)\n        else:\n            lower = merged[-1]\n            if higher[0] <= lower[1]:\n                if lower[2] is higher[2]:\n                    upper_bound = max(lower[1], higher[1])\n                    merged[-1] = (lower[0], upper_bound, lower[2])\n                else:\n                    if lower[1] > higher[1]:\n                        merged[-1] = lower\n                    else:\n                        merged[-1] = (lower[0], higher[1], higher[2])\n            else:\n                merged.append(higher)\n\n    return merged","metadata":{"id":"mtZHxmbR2_UY","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.970051Z","iopub.execute_input":"2025-05-06T23:59:28.970326Z","iopub.status.idle":"2025-05-06T23:59:28.976263Z","shell.execute_reply.started":"2025-05-06T23:59:28.970306Z","shell.execute_reply":"2025-05-06T23:59:28.975612Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"# From 'annotation' column, we are extracting the starting index, ending index, entity label\n# So that we can convert the content in BILOU format\n\ndef get_entities(df):\n    \n    entities = []\n    \n    for i in range(len(df)):\n        entity = []\n    \n        for annot in df['annotation'][i]:\n            try:\n                ent = entity_dict[annot['label'][0]]\n                start = annot['points'][0]['start']\n                end = annot['points'][0]['end'] + 1\n                entity.append((start, end, ent))\n            except:\n                pass\n    \n        entity = mergeIntervals(entity)\n        entities.append(entity)\n    \n    return entities","metadata":{"id":"3UvJzL_BPXnW","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:28.976930Z","iopub.execute_input":"2025-05-06T23:59:28.977220Z","iopub.status.idle":"2025-05-06T23:59:29.000283Z","shell.execute_reply.started":"2025-05-06T23:59:28.977193Z","shell.execute_reply":"2025-05-06T23:59:28.999778Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"#Adding an new col for 'entities'\ndf['entities']=get_entities(df)\ndf.head()","metadata":{"id":"UeABgzFCMUbT","colab":{"base_uri":"https://localhost:8080/","height":423},"executionInfo":{"status":"ok","timestamp":1683800377390,"user_tz":-480,"elapsed":384,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"1277c32c-6fd4-49bc-f482-49f62f60d9b7","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:29.000895Z","iopub.execute_input":"2025-05-06T23:59:29.001101Z","iopub.status.idle":"2025-05-06T23:59:29.081168Z","shell.execute_reply.started":"2025-05-06T23:59:29.001087Z","shell.execute_reply":"2025-05-06T23:59:29.080654Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"                                             content  \\\n0  Abhishek Jha\\nApplication Development Associat...   \n1  Afreen Jamadar\\nActive member of IIIT Committe...   \n2  Akhil Yadav Polemaina\\nHyderabad, Telangana - ...   \n3  Alok Khandai\\nOperational Analyst (SQL DBA) En...   \n4  Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...   \n\n                                          annotation  \\\n0  [{'label': ['Skills'], 'points': [{'start': 12...   \n1  [{'label': ['Email Address'], 'points': [{'sta...   \n2  [{'label': ['Skills'], 'points': [{'start': 37...   \n3  [{'label': ['Skills'], 'points': [{'start': 80...   \n4  [{'label': ['Degree'], 'points': [{'start': 20...   \n\n                                            entities  \n0  [(0, 12, NAME), (13, 46, DESIG), (49, 58, COMP...  \n1  [(0, 14, NAME), (62, 68, LOC), (104, 148, EMAI...  \n2  [(0, 21, NAME), (22, 31, LOC), (65, 117, EMAIL...  \n3  [(0, 12, NAME), (13, 51, DESIG), (54, 60, COMP...  \n4  [(0, 13, NAME), (14, 22, DESIG), (24, 41, COMP...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>content</th>\n      <th>annotation</th>\n      <th>entities</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Abhishek Jha\\nApplication Development Associat...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 12...</td>\n      <td>[(0, 12, NAME), (13, 46, DESIG), (49, 58, COMP...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Afreen Jamadar\\nActive member of IIIT Committe...</td>\n      <td>[{'label': ['Email Address'], 'points': [{'sta...</td>\n      <td>[(0, 14, NAME), (62, 68, LOC), (104, 148, EMAI...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Akhil Yadav Polemaina\\nHyderabad, Telangana - ...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 37...</td>\n      <td>[(0, 21, NAME), (22, 31, LOC), (65, 117, EMAIL...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Alok Khandai\\nOperational Analyst (SQL DBA) En...</td>\n      <td>[{'label': ['Skills'], 'points': [{'start': 80...</td>\n      <td>[(0, 12, NAME), (13, 51, DESIG), (54, 60, COMP...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Ananya Chavan\\nlecturer - oracle tutorials\\n\\n...</td>\n      <td>[{'label': ['Degree'], 'points': [{'start': 20...</td>\n      <td>[(0, 13, NAME), (14, 22, DESIG), (24, 41, COMP...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"df.iloc[0]['entities']","metadata":{"id":"yrdAODUKMsR5","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683633456683,"user_tz":-480,"elapsed":561,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"aca21acc-182a-4b79-a141-3220160fc345","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:29.081829Z","iopub.execute_input":"2025-05-06T23:59:29.082028Z","iopub.status.idle":"2025-05-06T23:59:29.086864Z","shell.execute_reply.started":"2025-05-06T23:59:29.082007Z","shell.execute_reply":"2025-05-06T23:59:29.086057Z"}},"outputs":[{"execution_count":17,"output_type":"execute_result","data":{"text/plain":"[(0, 12, 'NAME'),\n (13, 46, 'DESIG'),\n (49, 58, 'COMPANY'),\n (60, 69, 'LOC'),\n (95, 146, 'EMAIL'),\n (372, 405, 'DESIG'),\n (407, 416, 'COMPANY'),\n (727, 770, 'DESIG'),\n (771, 814, 'CLG'),\n (856, 861, 'GRADYEAR'),\n (883, 905, 'CLG'),\n (939, 957, 'CLG'),\n (993, 1154, 'SKILLS'),\n (1295, 1622, 'SKILLS')]"},"metadata":{}}],"execution_count":17},{"cell_type":"code","source":"'''\nhttps://spacy.io/api/top-level\nReturns a list of strings, describing the tags. Each tag will be in the form of either '','0' or {action}-{label},\nwhere action is one of 'B', 'I', 'L', 'U'.\n- '-' us used where the entity offsets don't alighn with the tokenization in the Doc obj. The training algo will view as missing values.\n- 0 denotes a non-entity token.\n- B denotes the beginnning of a multi-token entity.\n- I the inside of an entity of 3 or more tokens.\n- L the end of an entity of 2 or more tokens.\n- U denotes single-token entity.\n\nExample\n==============\ndoc=nlp('I like London') \nentities=[(7,13,'LOC')] \ntags=offsets_to_biluo_tags(doc,entities) #['O', 'O', 'U-LOC'] \n'''\ndef get_train_data(df):\n    tags = []\n    sentences = []\n\n    for i in range(len(df)):\n        text = df['content'][i]\n        entities = df['entities'][i]\n    \n        doc = nlp(text)\n    \n        tag = offsets_to_biluo_tags(doc, entities)\n        tmp = pd.DataFrame([list(doc), tag]).T\n        loc = []\n        for i in range(len(tmp)):\n            if tmp[0][i].text is '.' and tmp[1][i] is 'O':\n                loc.append(i)\n        loc.append(len(doc))\n    \n        last = 0\n        data = []\n        for pos in loc:\n            data.append([list(doc)[last:pos], tag[last:pos]])\n            last = pos\n    \n        for d in data:\n            tag = ['O' if t is '-' else t for t in d[1]]\n            if len(set(tag)) > 1:\n                sentences.append(d[0])\n                tags.append(tag)\n    \n    return sentences, tags","metadata":{"id":"2f9e7tXe3kWD","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:29.087693Z","iopub.execute_input":"2025-05-06T23:59:29.087922Z","iopub.status.idle":"2025-05-06T23:59:29.103323Z","shell.execute_reply.started":"2025-05-06T23:59:29.087907Z","shell.execute_reply":"2025-05-06T23:59:29.102656Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"sentences, tags = get_train_data(df)\nprint(len(sentences), len(tags))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nFrLgTxMMeSd","executionInfo":{"status":"ok","timestamp":1683800416527,"user_tz":-480,"elapsed":32618,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"10c42b92-7607-4b01-e813-1d2db4bd11e2","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:29.104055Z","iopub.execute_input":"2025-05-06T23:59:29.104400Z","iopub.status.idle":"2025-05-06T23:59:58.417001Z","shell.execute_reply.started":"2025-05-06T23:59:29.104373Z","shell.execute_reply":"2025-05-06T23:59:58.416287Z"}},"outputs":[{"name":"stdout","text":"779 779\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"print(sentences[0])\nprint(tags[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OBJW6A-KTbnf","executionInfo":{"status":"ok","timestamp":1683633592331,"user_tz":-480,"elapsed":400,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"554c92d3-fb09-437e-8338-e18f9eab5570","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.417755Z","iopub.execute_input":"2025-05-06T23:59:58.417954Z","iopub.status.idle":"2025-05-06T23:59:58.422201Z","shell.execute_reply.started":"2025-05-06T23:59:58.417939Z","shell.execute_reply":"2025-05-06T23:59:58.421424Z"}},"outputs":[{"name":"stdout","text":"[Abhishek, Jha, \n, Application, Development, Associate, -, Accenture, \n, \n, Bengaluru, ,, Karnataka, -, Email, me, on, Indeed, :, indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a, \n, \n, •, To, work, for, an, organization, which, provides, me, the, opportunity, to, improve, my, skills, \n, and, knowledge, for, my, individual, and, company, 's, growth, in, best, possible, ways]\n['B-NAME', 'L-NAME', 'O', 'B-DESIG', 'I-DESIG', 'L-DESIG', 'O', 'U-COMPANY', 'O', 'O', 'U-LOC', 'O', 'O', 'O', 'O', 'O', 'O', 'B-EMAIL', 'I-EMAIL', 'I-EMAIL', 'L-EMAIL', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n","output_type":"stream"}],"execution_count":20},{"cell_type":"code","source":"#Find all unique tags\ntag_vals = set(['X', '[CLS]', '[SEP]'])\nfor i in range(len(tags)):\n    tag_vals = tag_vals.union(tags[i])\n\n#tag2idx convert tag to idx, is a dict contains (tag,idx)\ntag2idx={t:i for i,t in enumerate(tag_vals)}\n\n#idx2tag convert tag to idx, is a dict contains (idx,tag)\nidx2tag = {tag2idx[key] : key for key in tag2idx.keys()}","metadata":{"id":"Xvao3VfMMgwM","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.422980Z","iopub.execute_input":"2025-05-06T23:59:58.423182Z","iopub.status.idle":"2025-05-06T23:59:58.477707Z","shell.execute_reply.started":"2025-05-06T23:59:58.423160Z","shell.execute_reply":"2025-05-06T23:59:58.477141Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"print(tag_vals)\nprint(tag2idx)\nprint(idx2tag)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_dh-kwNsk1sO","executionInfo":{"status":"ok","timestamp":1683633613923,"user_tz":-480,"elapsed":396,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"20f98ee9-fdcf-419b-ebd5-46a56cd61630","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.478398Z","iopub.execute_input":"2025-05-06T23:59:58.478634Z","iopub.status.idle":"2025-05-06T23:59:58.498342Z","shell.execute_reply.started":"2025-05-06T23:59:58.478616Z","shell.execute_reply":"2025-05-06T23:59:58.497716Z"}},"outputs":[{"name":"stdout","text":"{'U-LOC', 'B-EMAIL', 'I-CLG', 'I-DEG', 'X', 'B-LOC', 'I-LOC', 'I-GRADYEAR', 'B-COMPANY', 'O', 'U-GRADYEAR', 'L-DESIG', 'U-SKILLS', 'B-CLG', 'L-CLG', 'I-COMPANY', 'L-NAME', 'I-EMAIL', 'U-COMPANY', '[CLS]', 'L-SKILLS', 'B-DEG', 'I-NAME', '[SEP]', 'B-GRADYEAR', 'I-SKILLS', 'B-DESIG', 'L-DEG', 'L-GRADYEAR', 'B-YOE', 'U-EMAIL', 'B-NAME', 'L-LOC', 'I-YOE', 'U-YOE', 'U-DEG', 'L-COMPANY', 'L-YOE', 'U-DESIG', 'U-CLG', 'B-SKILLS', 'L-EMAIL', 'I-DESIG'}\n{'U-LOC': 0, 'B-EMAIL': 1, 'I-CLG': 2, 'I-DEG': 3, 'X': 4, 'B-LOC': 5, 'I-LOC': 6, 'I-GRADYEAR': 7, 'B-COMPANY': 8, 'O': 9, 'U-GRADYEAR': 10, 'L-DESIG': 11, 'U-SKILLS': 12, 'B-CLG': 13, 'L-CLG': 14, 'I-COMPANY': 15, 'L-NAME': 16, 'I-EMAIL': 17, 'U-COMPANY': 18, '[CLS]': 19, 'L-SKILLS': 20, 'B-DEG': 21, 'I-NAME': 22, '[SEP]': 23, 'B-GRADYEAR': 24, 'I-SKILLS': 25, 'B-DESIG': 26, 'L-DEG': 27, 'L-GRADYEAR': 28, 'B-YOE': 29, 'U-EMAIL': 30, 'B-NAME': 31, 'L-LOC': 32, 'I-YOE': 33, 'U-YOE': 34, 'U-DEG': 35, 'L-COMPANY': 36, 'L-YOE': 37, 'U-DESIG': 38, 'U-CLG': 39, 'B-SKILLS': 40, 'L-EMAIL': 41, 'I-DESIG': 42}\n{0: 'U-LOC', 1: 'B-EMAIL', 2: 'I-CLG', 3: 'I-DEG', 4: 'X', 5: 'B-LOC', 6: 'I-LOC', 7: 'I-GRADYEAR', 8: 'B-COMPANY', 9: 'O', 10: 'U-GRADYEAR', 11: 'L-DESIG', 12: 'U-SKILLS', 13: 'B-CLG', 14: 'L-CLG', 15: 'I-COMPANY', 16: 'L-NAME', 17: 'I-EMAIL', 18: 'U-COMPANY', 19: '[CLS]', 20: 'L-SKILLS', 21: 'B-DEG', 22: 'I-NAME', 23: '[SEP]', 24: 'B-GRADYEAR', 25: 'I-SKILLS', 26: 'B-DESIG', 27: 'L-DEG', 28: 'L-GRADYEAR', 29: 'B-YOE', 30: 'U-EMAIL', 31: 'B-NAME', 32: 'L-LOC', 33: 'I-YOE', 34: 'U-YOE', 35: 'U-DEG', 36: 'L-COMPANY', 37: 'L-YOE', 38: 'U-DESIG', 39: 'U-CLG', 40: 'B-SKILLS', 41: 'L-EMAIL', 42: 'I-DESIG'}\n","output_type":"stream"}],"execution_count":22},{"cell_type":"markdown","source":"# Make training data\n- Set GPU environment\n- Load tokenizer and tokenize\n- Set 3 embedding - Token embedding, Mask word embedding, Segmentation embedding\n- Split dataset into train and validate, then send them to DataLoader","metadata":{"id":"Krt_ECCnR8dJ"}},{"cell_type":"code","source":"device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nn_gpu=torch.cuda.device_count()\nn_gpu","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jpjcv-UPMp3S","executionInfo":{"status":"ok","timestamp":1683633651337,"user_tz":-480,"elapsed":452,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"efe564cd-bfd5-4935-d2d8-b6655807b290","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.498925Z","iopub.execute_input":"2025-05-06T23:59:58.499136Z","iopub.status.idle":"2025-05-06T23:59:58.518936Z","shell.execute_reply.started":"2025-05-06T23:59:58.499122Z","shell.execute_reply":"2025-05-06T23:59:58.518147Z"}},"outputs":[{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"2"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"#BERT pre-trained tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BgxS-xvyMrtw","executionInfo":{"status":"ok","timestamp":1683633662364,"user_tz":-480,"elapsed":1556,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"aaaed706-5dd2-4a39-d187-95b085158036","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.519657Z","iopub.execute_input":"2025-05-06T23:59:58.519860Z","iopub.status.idle":"2025-05-06T23:59:58.864678Z","shell.execute_reply.started":"2025-05-06T23:59:58.519839Z","shell.execute_reply":"2025-05-06T23:59:58.863793Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 213450/213450 [00:00<00:00, 2705107.28B/s]\n","output_type":"stream"}],"execution_count":24},{"cell_type":"markdown","source":"## Tokenizer Text\n\n- In hunggieface for bert, when come across OOV, will word piece the word.\n\n- We need to adjust the labels base on the tokenize result, “##abc” need to set label \"X\".\n\n- Need to set \"[CLS]\" at front and \"[SEP]\" at the end, as what the paper do, BERT indexer should add [CLS] and [SEP] tokens.","metadata":{"id":"KorMPZTLSnc_"}},{"cell_type":"code","source":"def get_tokenized_train_data(sentences, tags):\n\n    tokenized_texts = []\n    word_piece_labels = []\n\n    for word_list, label in zip(sentences, tags):\n    \n        # Add [CLS] at the front\n        temp_lable = ['[CLS]']\n        temp_token = ['[CLS]']\n    \n        for word, lab in zip(word_list, label):\n            token_list = tokenizer.tokenize(word.text)\n            for m, token in enumerate(token_list):\n                temp_token.append(token)\n                if m == 0:\n                    temp_lable.append(lab)\n                else:\n                    temp_lable.append('X')  \n                \n        # Add [SEP] at the end\n        temp_lable.append('[SEP]')\n        temp_token.append('[SEP]')\n    \n        tokenized_texts.append(temp_token)\n        word_piece_labels.append(temp_lable)\n    \n    return tokenized_texts, word_piece_labels","metadata":{"id":"EyzQTw_r3tdn","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.865645Z","iopub.execute_input":"2025-05-06T23:59:58.866476Z","iopub.status.idle":"2025-05-06T23:59:58.871275Z","shell.execute_reply.started":"2025-05-06T23:59:58.866455Z","shell.execute_reply":"2025-05-06T23:59:58.870671Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"tokenized_texts, word_piece_labels = get_tokenized_train_data(sentences, tags)","metadata":{"id":"bGop1FFfShgC","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:58.871913Z","iopub.execute_input":"2025-05-06T23:59:58.872125Z","iopub.status.idle":"2025-05-06T23:59:59.515314Z","shell.execute_reply.started":"2025-05-06T23:59:58.872110Z","shell.execute_reply":"2025-05-06T23:59:59.514750Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"#Vector representations of the corresponding words from the input\nprint(tokenized_texts[0])\nprint(word_piece_labels[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K1tLGZRJSjiv","executionInfo":{"status":"ok","timestamp":1683633791062,"user_tz":-480,"elapsed":405,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"54d276c1-b017-4f15-871c-6abee4117f2e","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.519116Z","iopub.execute_input":"2025-05-06T23:59:59.519318Z","iopub.status.idle":"2025-05-06T23:59:59.524510Z","shell.execute_reply.started":"2025-05-06T23:59:59.519304Z","shell.execute_reply":"2025-05-06T23:59:59.523430Z"}},"outputs":[{"name":"stdout","text":"['[CLS]', 'A', '##b', '##his', '##he', '##k', 'J', '##ha', 'Application', 'Development', 'Associate', '-', 'A', '##cc', '##ent', '##ure', 'Bengal', '##uru', ',', 'Karnataka', '-', 'Em', '##ail', 'me', 'on', 'Indeed', ':', 'indeed', '.', 'com', '/', 'r', '/', 'A', '##b', '##his', '##he', '##k', '-', 'J', '##ha', '/', '10', '##e', '##7', '##a', '##8', '##c', '##b', '##7', '##32', '##b', '##c', '##43', '##a', '•', 'To', 'work', 'for', 'an', 'organization', 'which', 'provides', 'me', 'the', 'opportunity', 'to', 'improve', 'my', 'skills', 'and', 'knowledge', 'for', 'my', 'individual', 'and', 'company', \"'\", 's', 'growth', 'in', 'best', 'possible', 'ways', '[SEP]']\n['[CLS]', 'B-NAME', 'X', 'X', 'X', 'X', 'L-NAME', 'X', 'B-DESIG', 'I-DESIG', 'L-DESIG', 'O', 'U-COMPANY', 'X', 'X', 'X', 'U-LOC', 'X', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'B-EMAIL', 'I-EMAIL', 'I-EMAIL', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'X', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'X', 'O', 'O', 'O', 'O', 'O', '[SEP]']\n","output_type":"stream"}],"execution_count":27},{"cell_type":"markdown","source":"## Set Token Embedding\n- Pad or trim the text and label to fit the need for MAX_LEN","metadata":{"id":"IMo94vaSSvEk"}},{"cell_type":"code","source":"MAX_LEN = 512\nbs = 4\n\n#Make text tokens into ids\ninput_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                          maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\nprint(len(input_ids[0]))\nprint(input_ids[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s-22PV3o301V","executionInfo":{"status":"ok","timestamp":1683633801033,"user_tz":-480,"elapsed":425,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"b12ab855-7a68-49e2-93a6-b66530ccfc63","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.525515Z","iopub.execute_input":"2025-05-06T23:59:59.526448Z","iopub.status.idle":"2025-05-06T23:59:59.619290Z","shell.execute_reply.started":"2025-05-06T23:59:59.526427Z","shell.execute_reply":"2025-05-06T23:59:59.618600Z"}},"outputs":[{"name":"stdout","text":"512\n[  101   138  1830 27516  4638  1377   147  2328 22491  3273  9666   118\n   138 19515  3452  3313  7756 12328   117 12247   118 18653 11922  1143\n  1113 10364   131  5750   119  3254   120   187   120   138  1830 27516\n  4638  1377   118   147  2328   120  1275  1162  1559  1161  1604  1665\n  1830  1559 17101  1830  1665 25631  1161   794  1706  1250  1111  1126\n  2369  1134  2790  1143  1103  3767  1106  4607  1139  4196  1105  3044\n  1111  1139  2510  1105  1419   112   188  3213  1107  1436  1936  3242\n   102     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0     0     0     0     0\n     0     0     0     0     0     0     0     0]\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"'''\npad_sequences -> https://www.tensorflow.org/api_docs/python/tf/keras/utils/pad_sequences\n====================\nmaxlen=512: maximum length of all sequences\npadding    ='post': pad after each sequence\ntruncating ='post': remove values from sequences larger than maxlen at the end of the sequences\n\nconvert_tokens_to_ids -> converts a string to a sequence of ids (int)\n'''\n\ntags = pad_sequences([[tag2idx.get(l) for l in lab] for lab in word_piece_labels], maxlen=MAX_LEN, value=tag2idx[\"O\"], \n                     padding=\"post\", dtype=\"long\", truncating=\"post\")\nprint(len(tags[0]))\nprint(tags[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bCwtmUeb_KjT","executionInfo":{"status":"ok","timestamp":1683633807374,"user_tz":-480,"elapsed":1407,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"f1f5ea29-2e8d-4a2b-e7ba-5931431468f7","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.620100Z","iopub.execute_input":"2025-05-06T23:59:59.620379Z","iopub.status.idle":"2025-05-06T23:59:59.644846Z","shell.execute_reply.started":"2025-05-06T23:59:59.620355Z","shell.execute_reply":"2025-05-06T23:59:59.644233Z"}},"outputs":[{"name":"stdout","text":"512\n[19 31  4  4  4  4 16  4 26 42 11  9 18  4  4  4  0  4  9  9  9  9  4  9\n  9  1 17 17  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4  4\n  4  4  4  4  4  4  4  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  4  9  9  9  9  9 23  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9  9\n  9  9  9  9  9  9  9  9]\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## Set Mask Word Embeeding\n- For fine tune of predict, with token mask is 1, pad token is 0","metadata":{"id":"A_GZkJj-TBRX"}},{"cell_type":"code","source":"#if the current value >0, then assign 1, else =0\nattention_masks=[[float(i>0) for i in ii] for ii in input_ids]\nprint(attention_masks[0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Djia1vFfntTl","executionInfo":{"status":"ok","timestamp":1683633840086,"user_tz":-480,"elapsed":1123,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"49e00bc4-4ec0-48b8-f4b0-ff2ee21256e9","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.645511Z","iopub.execute_input":"2025-05-06T23:59:59.645779Z","iopub.status.idle":"2025-05-06T23:59:59.797108Z","shell.execute_reply.started":"2025-05-06T23:59:59.645762Z","shell.execute_reply":"2025-05-06T23:59:59.796496Z"}},"outputs":[{"name":"stdout","text":"[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## Split data into Train and Validate\n- 70% for training, 30% for validation","metadata":{"id":"O26057JiTOW-"}},{"cell_type":"code","source":"#train inputs, validation inputs, train tags, validation tags, train masks, validation masks\ntr_inputs,val_inputs,tr_tags,val_tags,tr_masks,val_masks=train_test_split(input_ids,tags,attention_masks, random_state=2000, test_size=0.3)","metadata":{"id":"ltnloMgxqmCQ","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.798219Z","iopub.execute_input":"2025-05-06T23:59:59.798476Z","iopub.status.idle":"2025-05-06T23:59:59.804096Z","shell.execute_reply.started":"2025-05-06T23:59:59.798460Z","shell.execute_reply":"2025-05-06T23:59:59.803279Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"len(tr_inputs),len(val_inputs),len(tr_tags),len(val_tags),len(tr_masks),len(val_masks)","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oDkL4P0kTce_","executionInfo":{"status":"ok","timestamp":1683633896940,"user_tz":-480,"elapsed":5,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"07493ae8-76ab-4506-f3d1-880fae090741","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.804993Z","iopub.execute_input":"2025-05-06T23:59:59.805425Z","iopub.status.idle":"2025-05-06T23:59:59.821457Z","shell.execute_reply.started":"2025-05-06T23:59:59.805409Z","shell.execute_reply":"2025-05-06T23:59:59.820717Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"(545, 234, 545, 234, 545, 234)"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"### Set data into tensor","metadata":{"id":"3tOJPf6UTsKL"}},{"cell_type":"code","source":"tr_inputs=torch.tensor(tr_inputs)\nval_inputs=torch.tensor(val_inputs)\ntr_tags=torch.tensor(tr_tags)\nval_tags=torch.tensor(val_tags)\ntr_masks=torch.tensor(tr_masks)\nval_masks=torch.tensor(val_masks)           ","metadata":{"id":"2oBhftchoEng","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.822223Z","iopub.execute_input":"2025-05-06T23:59:59.822506Z","iopub.status.idle":"2025-05-06T23:59:59.955183Z","shell.execute_reply.started":"2025-05-06T23:59:59.822482Z","shell.execute_reply":"2025-05-06T23:59:59.954607Z"}},"outputs":[],"execution_count":33},{"cell_type":"markdown","source":"### Put data into Data Loader","metadata":{"id":"Co1bYql3TzEK"}},{"cell_type":"code","source":"'''\nTORCH.UTILS.DATA -> https://pytorch.org/docs/stable/data.html\n\nTensorDataset: Dataset wrapping tensors. Each sample will be retrieved by indexing tensors along the first dimension.\nRandomSampler: Samples elements randomly\nDataLoader   : Python iterable over a dataset\n\nNotes: Only set token embeeding, attention embedding, no segment embedding\n'''\n\ntrain_data=TensorDataset(tr_inputs,tr_masks,tr_tags)\ntrain_sampler=RandomSampler(train_data) \ntrain_dataloader=DataLoader(train_data,sampler=train_sampler,batch_size=bs) \n\nvalid_data=TensorDataset(val_inputs,val_masks,val_tags)\nvalid_sampler=SequentialSampler(valid_data)\nvalid_dataloader=DataLoader(valid_data,sampler=valid_sampler,batch_size=bs)","metadata":{"id":"gZUw0kZhuPn7","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.955914Z","iopub.execute_input":"2025-05-06T23:59:59.956111Z","iopub.status.idle":"2025-05-06T23:59:59.964866Z","shell.execute_reply.started":"2025-05-06T23:59:59.956095Z","shell.execute_reply":"2025-05-06T23:59:59.964105Z"}},"outputs":[],"execution_count":34},{"cell_type":"markdown","source":"# Train Model\n","metadata":{"id":"cGrUClN7UAqz"}},{"cell_type":"code","source":"#Defining the model\nbert_model = BertForTokenClassification.from_pretrained(\"bert-base-cased\", num_labels=len(tag2idx))","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PaJDiVCItdGI","executionInfo":{"status":"ok","timestamp":1683634013903,"user_tz":-480,"elapsed":17978,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"3400c11e-ac90-44fd-ea91-e650f80af005","trusted":true,"execution":{"iopub.status.busy":"2025-05-06T23:59:59.965555Z","iopub.execute_input":"2025-05-06T23:59:59.965819Z","iopub.status.idle":"2025-05-07T00:00:16.275760Z","shell.execute_reply.started":"2025-05-06T23:59:59.965796Z","shell.execute_reply":"2025-05-07T00:00:16.275082Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 404400730/404400730 [00:09<00:00, 42424269.24B/s]\n","output_type":"stream"}],"execution_count":35},{"cell_type":"code","source":"#Set model to GPU\nbert_model.cuda();","metadata":{"id":"5rWymqnLtkec","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:00:16.276576Z","iopub.execute_input":"2025-05-07T00:00:16.276798Z","iopub.status.idle":"2025-05-07T00:00:16.597346Z","shell.execute_reply.started":"2025-05-07T00:00:16.276780Z","shell.execute_reply":"2025-05-07T00:00:16.596557Z"}},"outputs":[],"execution_count":36},{"cell_type":"markdown","source":"### Set Fine-Tuning method\n- Manual optimizer","metadata":{"id":"T9Q6usKMU7T9"}},{"cell_type":"code","source":"FULL_FINETUNING=True\n#If full tuning=True: Fine tuning all the layers\nif FULL_FINETUNING:\n  param_optimizer=list(bert_model.named_parameters())\n  no_decay=['bias','gamma','beta']\n\n  #n=name, p=parameter\n  optimizer_grouped_parameters=[\n      #Params that not inside no_decay\n      {'params':[p for n,p in param_optimizer if not any(nd in n for nd in no_decay)],\n       'weight_decay_rate':0.01},\n\n       #Params that are inside no_decay\n       {'params':[p for n,p in param_optimizer if any(nd in n for nd in no_decay)],\n        'weight_decay_rate':0.0}\n        ]\n\n#If full tuning=False -> Not full tuning, only fine tune classifier params\nelse:\n  param_optimizer=list(bert_model.named_parameters())\n  optimizer_grouped_parameters=[{'params':[p for n,p in param_optimizer]}]\n\n#Optimizer and learning scheduler\noptimizer=Adam(optimizer_grouped_parameters,lr=3e-5)","metadata":{"id":"UfxcGY1eCwV3","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:00:16.598154Z","iopub.execute_input":"2025-05-07T00:00:16.598438Z","iopub.status.idle":"2025-05-07T00:00:19.615093Z","shell.execute_reply.started":"2025-05-07T00:00:16.598410Z","shell.execute_reply":"2025-05-07T00:00:19.614521Z"}},"outputs":[],"execution_count":37},{"cell_type":"markdown","source":"### Fine-Tuning Model","metadata":{"id":"QLK-_vGBVZC9"}},{"cell_type":"code","source":"#Set epoch and grad max num\nepochs=10\nmax_grad_norm=1.0\n\nfor _ in trange(epochs, desc='Epoch'):\n  #Train loop\n  bert_model.train()\n  tr_loss=0\n  nb_tr_examples,nb_tr_steps=0,0\n\n  for step, batch in enumerate(train_dataloader):\n    #Add batch to GPU\n    batch=tuple(t.to(device) for t in batch)\n    b_input_ids,b_input_mask,b_labels=batch\n    \n    #Forward pass\n    loss=bert_model(b_input_ids,token_type_ids=None,attention_mask=b_input_mask,labels=b_labels)\n\n    #Backward pass\n    loss.backward()\n\n    #Track train loss\n    tr_loss+=loss.item()\n\n    nb_tr_examples+=b_input_ids.size(0)\n    nb_tr_steps+=1\n\n    #Gradient clipping\n    torch.nn.utils.clip_grad_norm_(parameters=bert_model.parameters(),max_norm=max_grad_norm)\n\n    #Update parameters\n    optimizer.step()\n    bert_model.zero_grad()\n\n  #Print train loss per epoch\n  print('Train loss: {}'.format(tr_loss/nb_tr_steps))\n","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ZVjHhbPzJelT","executionInfo":{"status":"ok","timestamp":1683635758965,"user_tz":-480,"elapsed":623333,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"152d4de5-bbed-4f3f-d01c-9db1f3626d95","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:00:19.615951Z","iopub.execute_input":"2025-05-07T00:00:19.616656Z","iopub.status.idle":"2025-05-07T00:11:01.023886Z","shell.execute_reply.started":"2025-05-07T00:00:19.616622Z","shell.execute_reply":"2025-05-07T00:11:01.023059Z"}},"outputs":[{"name":"stderr","text":"Epoch:  10%|█         | 1/10 [01:00<09:05, 60.64s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.7907516077487138\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  20%|██        | 2/10 [02:05<08:25, 63.17s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.338385646360634\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  30%|███       | 3/10 [03:09<07:25, 63.63s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.25510957943833007\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  40%|████      | 4/10 [04:14<06:23, 63.91s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.18018710053097592\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  50%|█████     | 5/10 [05:18<05:20, 64.06s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.13469325292882692\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  60%|██████    | 6/10 [06:22<04:16, 64.23s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.10168079331680371\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  70%|███████   | 7/10 [07:27<03:13, 64.36s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.0890608644520823\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  80%|████████  | 8/10 [08:32<02:08, 64.45s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.06869292608632223\n","output_type":"stream"},{"name":"stderr","text":"Epoch:  90%|█████████ | 9/10 [09:36<01:04, 64.49s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.05553923775679874\n","output_type":"stream"},{"name":"stderr","text":"Epoch: 100%|██████████| 10/10 [10:41<00:00, 64.14s/it]","output_type":"stream"},{"name":"stdout","text":"Train loss: 0.04600018234311664\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}],"execution_count":38},{"cell_type":"markdown","source":"# Save Bert Model","metadata":{"id":"3Z1v6jatHy05"}},{"cell_type":"code","source":"bert_out_address='/kaggle/working/bert_model'\n\n#Save a trained model, configuration and tokenizer\nmodel_to_save=bert_model.module if hasattr(bert_model,'module') else bert_model\n\noutput_model_file='/kaggle/working/bert_model/pytorch_model.bin'\noutput_config_file='/kaggle/working/bert_model/config.json'\n\n#Save model into file\ntorch.save(model_to_save.state_dict(),output_model_file)\n\nmodel_to_save.config.to_json_file(output_config_file)\n\ntokenizer.save_vocabulary(bert_out_address)\n\n#Load back the bert model\nbert_model=BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))\n\nbert_model.cuda();\n\nif n_gpu >1:\n    bert_model = torch.nn.DataParallel(bert_model)","metadata":{"id":"O3v-lHOQV2jP","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:46:12.750104Z","iopub.execute_input":"2025-05-07T00:46:12.750786Z","iopub.status.idle":"2025-05-07T00:46:16.194020Z","shell.execute_reply.started":"2025-05-07T00:46:12.750762Z","shell.execute_reply":"2025-05-07T00:46:16.193423Z"}},"outputs":[],"execution_count":54},{"cell_type":"code","source":"bert_out_address = '/kaggle/working/bert_model/'\n\n# Load back the BERT model from the working directory\nbert_model = BertForTokenClassification.from_pretrained(bert_out_address, num_labels=len(tag2idx))\n","metadata":{"id":"GegxpwJBVBVD","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:46:23.595536Z","iopub.execute_input":"2025-05-07T00:46:23.596294Z","iopub.status.idle":"2025-05-07T00:46:25.906034Z","shell.execute_reply.started":"2025-05-07T00:46:23.596258Z","shell.execute_reply":"2025-05-07T00:46:25.905418Z"}},"outputs":[],"execution_count":55},{"cell_type":"markdown","source":"# Model Evaluation","metadata":{"id":"1cMtf0mOXd16"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom sklearn.metrics import f1_score, accuracy_score, classification_report\nfrom pytorch_pretrained_bert import BertTokenizer, BertForTokenClassification\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n\n# Define tags for BILUO scheme\nlabels = ['NAME', 'CLG', 'DEG', 'GRADYEAR', 'YOE', 'COMPANY', 'DESIG', 'SKILLS', 'LOC', 'EMAIL']\ntags = ['O'] + [f\"{prefix}-{label}\" for label in labels for prefix in ['B', 'I', 'L', 'U']] + ['[CLS]', '[SEP]', 'X']\ntag2idx = {tag: idx for idx, tag in enumerate(tags)}\nidx2tag = {idx: tag for tag, idx in tag2idx.items()}\n\n# Load and move model to device\nbert_model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(tag2idx))\nbert_model = bert_model.to(device)\n\n# Set model to evaluation mode\nbert_model.eval()\n\ny_true = []\ny_pred = []\n\neval_loss, eval_accuracy = 0, 0\nnb_eval_steps, nb_eval_examples = 0, 0\n\n# Assuming valid_dataloader is defined as in your notebook\nfor batch in valid_dataloader:\n    batch = tuple(t.to(device) for t in batch)\n    input_ids, input_mask, label_ids = batch\n\n    with torch.no_grad():\n        logits = bert_model(input_ids=input_ids, attention_mask=input_mask)\n        logits = logits.detach().cpu().numpy()\n\n    logits = np.argmax(logits, axis=2)\n\n    label_ids = label_ids.to('cpu').numpy()\n    input_mask = input_mask.to('cpu').numpy()\n\n    for i, mask in enumerate(input_mask):\n        for j, m in enumerate(mask):\n            if m:  # Only consider valid tokens (non-padded)\n                true_label = idx2tag[label_ids[i][j]]\n                pred_label = idx2tag[logits[i][j]]\n                if true_label not in ['X', '[CLS]', '[SEP]']:\n                    y_true.append(true_label)\n                    y_pred.append(pred_label)\n\n# Print evaluation results\nprint(\"F1 Score: %f\" % f1_score(y_true, y_pred, average='weighted'))\nprint(\"Accuracy Score: %f\" % accuracy_score(y_true, y_pred))\nprint(\"\\nClassification Report:\")\nprint(classification_report(y_true, y_pred, digits=4))","metadata":{"id":"ZLEYI60sPUrT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683636183688,"user_tz":-480,"elapsed":9174,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"2d94824a-7d88-4d06-f835-8ca2ff5b2627","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:54:22.332114Z","iopub.execute_input":"2025-05-07T00:54:22.332866Z","iopub.status.idle":"2025-05-07T00:54:39.395108Z","shell.execute_reply.started":"2025-05-07T00:54:22.332841Z","shell.execute_reply":"2025-05-07T00:54:39.394388Z"}},"outputs":[{"name":"stdout","text":"F1 Score: 0.004721\nAccuracy Score: 0.004262\n\nClassification Report:\n              precision    recall  f1-score   support\n\n       B-CLG     0.0000    0.0000    0.0000        12\n   B-COMPANY     0.0000    0.0000    0.0000        46\n       B-DEG     0.0000    0.0000    0.0000     10760\n     B-DESIG     0.3913    0.0055    0.0109      1629\n     B-EMAIL     0.0000    0.0000    0.0000         8\n  B-GRADYEAR     0.0000    0.0000    0.0000        63\n       B-LOC     0.0000    0.0000    0.0000         0\n      B-NAME     0.0006    0.0625    0.0011        32\n    B-SKILLS     0.0000    0.0000    0.0000         8\n       B-YOE     0.0000    0.0000    0.0000        11\n       I-CLG     0.0000    0.0000    0.0000         7\n   I-COMPANY     0.0000    0.0000    0.0000         5\n       I-DEG     0.0000    0.0000    0.0000        47\n     I-DESIG     0.0099    0.0164    0.0123       122\n     I-EMAIL     0.0000    0.0000    0.0000         8\n  I-GRADYEAR     0.0018    0.0192    0.0033        52\n       I-LOC     0.0000    0.0000    0.0000         1\n      I-NAME     0.0000    0.0000    0.0000       132\n    I-SKILLS     0.0000    0.0000    0.0000        16\n       I-YOE     0.0029    0.0275    0.0053       109\n       L-CLG     0.0000    0.0000    0.0000         1\n   L-COMPANY     0.0000    0.0000    0.0000       230\n       L-DEG     0.0069    0.3535    0.0136        99\n     L-DESIG     0.0004    0.0333    0.0009        30\n     L-EMAIL     0.0000    0.0000    0.0000         2\n  L-GRADYEAR     0.0000    0.0000    0.0000        47\n       L-LOC     0.0000    0.0000    0.0000        20\n      L-NAME     0.0024    0.0072    0.0036       139\n    L-SKILLS     0.0000    0.0000    0.0000        75\n       L-YOE     0.0000    0.0000    0.0000       234\n           O     0.0000    0.0000    0.0000       100\n       U-CLG     0.0005    0.0192    0.0010        52\n   U-COMPANY     0.0000    0.0000    0.0000         6\n       U-DEG     0.0000    0.0000    0.0000        49\n     U-DESIG     0.0000    0.0000    0.0000         3\n     U-EMAIL     0.0014    0.0484    0.0027        62\n  U-GRADYEAR     0.0000    0.0000    0.0000        75\n       U-LOC     0.0000    0.0000    0.0000        40\n      U-NAME     0.6364    0.0045    0.0089     10945\n    U-SKILLS     0.0000    0.0000    0.0000        12\n       U-YOE     0.0021    0.0196    0.0038        51\n           X     0.0000    0.0000    0.0000         0\n       [CLS]     0.0000    0.0000    0.0000         0\n       [SEP]     0.0000    0.0000    0.0000         0\n\n    accuracy                         0.0043     25340\n   macro avg     0.0240    0.0140    0.0015     25340\nweighted avg     0.3001    0.0043    0.0047     25340\n\n","output_type":"stream"}],"execution_count":58},{"cell_type":"markdown","source":"BERT preprocessing","metadata":{"id":"S4Bh9Q9tBVpp"}},{"cell_type":"code","source":"# JSON formatting functions\nimport logging\nimport re\ndef convert_dataturks_to_spacy(dataturks_JSON_FilePath):\n    try:\n        training_data = []\n        lines=[]\n        with open(dataturks_JSON_FilePath, 'r',encoding='utf-8') as f:\n          lines = f.readlines()\n\n        for line in lines:\n            data = json.loads(line)\n            text = data['content'].replace(\"\\n\", \" \")\n            entities = []\n            data_annotations = data['annotation']\n            if data_annotations is not None:\n                for annotation in data_annotations:\n                    #only a single point in text annotation.\n                    point = annotation['points'][0]\n                    labels = annotation['label']\n                    # handle both list of labels or a single label.\n                    if not isinstance(labels, list):\n                        labels = [labels]\n\n                    for label in labels:\n                        point_start = point['start']\n                        point_end = point['end']\n                        point_text = point['text']\n                        \n                        lstrip_diff = len(point_text) - len(point_text.lstrip())\n                        rstrip_diff = len(point_text) - len(point_text.rstrip())\n                        if lstrip_diff != 0:\n                            point_start = point_start + lstrip_diff\n                        if rstrip_diff != 0:\n                            point_end = point_end - rstrip_diff\n                        entities.append((point_start, point_end + 1 , label))\n            training_data.append((text, {\"entities\" : entities}))\n        return training_data\n    except Exception as e:\n        logging.exception(\"Unable to process \" + dataturks_JSON_FilePath + \"\\n\" + \"error = \" + str(e))\n        return None\n\ndef trim_entity_spans(data: list) -> list:\n    \"\"\"Removes leading and trailing white spaces from entity spans.\n\n    Args:\n        data (list): The data to be cleaned in spaCy JSON format.\n\n    Returns:\n        list: The cleaned data.\n    \"\"\"\n    invalid_span_tokens = re.compile(r'\\s')\n\n    cleaned_data = []\n    for text, annotations in data:\n        entities = annotations['entities']\n        valid_entities = []\n        for start, end, label in entities:\n            valid_start = start\n            valid_end = end\n            while valid_start < len(text) and invalid_span_tokens.match(\n                    text[valid_start]):\n                valid_start += 1\n            while valid_end > 1 and invalid_span_tokens.match(\n                    text[valid_end - 1]):\n                valid_end -= 1\n            valid_entities.append([valid_start, valid_end, label])\n        cleaned_data.append([text, {'entities': valid_entities}])\n    return cleaned_data     ","metadata":{"id":"RmNV8XAx5y8r","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:54:48.780174Z","iopub.execute_input":"2025-05-07T00:54:48.780733Z","iopub.status.idle":"2025-05-07T00:54:48.789471Z","shell.execute_reply.started":"2025-05-07T00:54:48.780710Z","shell.execute_reply":"2025-05-07T00:54:48.788728Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"data = trim_entity_spans(convert_dataturks_to_spacy(data_file_address))\ndata[0]","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iT2j_9A56NeF","executionInfo":{"status":"ok","timestamp":1683643292378,"user_tz":-480,"elapsed":464,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"1f1a366e-0df2-4142-c70a-1ded58800b3e","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:54:55.068789Z","iopub.execute_input":"2025-05-07T00:54:55.069199Z","iopub.status.idle":"2025-05-07T00:54:55.123336Z","shell.execute_reply.started":"2025-05-07T00:54:55.069141Z","shell.execute_reply":"2025-05-07T00:54:55.122613Z"}},"outputs":[{"execution_count":60,"output_type":"execute_result","data":{"text/plain":"[\"Abhishek Jha Application Development Associate - Accenture  Bengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a  • To work for an organization which provides me the opportunity to improve my skills and knowledge for my individual and company's growth in best possible ways.  Willing to relocate to: Bangalore, Karnataka  WORK EXPERIENCE  Application Development Associate  Accenture -  November 2017 to Present  Role: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries for the Bot which will be triggered based on given input. Also, Training the bot for different possible utterances (Both positive and negative), which will be given as input by the user.  EDUCATION  B.E in Information science and engineering  B.v.b college of engineering and technology -  Hubli, Karnataka  August 2013 to June 2017  12th in Mathematics  Woodbine modern school  April 2011 to March 2013  10th  Kendriya Vidyalaya  April 2001 to March 2011  SKILLS  C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year), Database Management System (Less than 1 year), Java (Less than 1 year)  ADDITIONAL INFORMATION  Technical Skills  https://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN   • Programming language: C, C++, Java • Oracle PeopleSoft • Internet Of Things • Machine Learning • Database Management System • Computer Networks • Operating System worked on: Linux, Windows, Mac  Non - Technical Skills  • Honest and Hard-Working • Tolerant and Flexible to Different Situations • Polite and Calm • Team-Player\",\n {'entities': [[1296, 1622, 'Skills'],\n   [993, 1154, 'Skills'],\n   [939, 957, 'College Name'],\n   [883, 905, 'College Name'],\n   [856, 860, 'Graduation Year'],\n   [771, 814, 'College Name'],\n   [727, 769, 'Designation'],\n   [407, 416, 'Companies worked at'],\n   [372, 405, 'Designation'],\n   [95, 145, 'Email Address'],\n   [60, 69, 'Location'],\n   [49, 58, 'Companies worked at'],\n   [13, 46, 'Designation'],\n   [0, 12, 'Name']]}]"},"metadata":{}}],"execution_count":60},{"cell_type":"markdown","source":"# Inference\n- After we trained a model, we can make it into service, sending the new resume then get the prediction.\n\nProcess\n\n1) Load model\n\n2) Load tokenizer\n\n3) Set test query (PDF file)\n\n4) Make query into embedding\n\n5) Predict with model\n\n6) Parser result\n","metadata":{"id":"oDY0e4qRYyIl"}},{"cell_type":"code","source":"def getWordnetPos(words):\n    tag=pos_tag([words])[0][1][0].upper()\n    tag_dict={\"J\":wordnet.ADJ,\n              \"N\":wordnet.NOUN,\n              \"V\":wordnet.VERB,\n              \"R\":wordnet.ADV\n             }\n    return tag_dict.get(tag,wordnet.NOUN)\n\ndef cv_preprocessing(cv_data):\n  #Tokenization\n  tokenized_text=word_tokenize(cv_data)\n\n  #Remove stopwords\n  stop_words = set(stopwords.words('english'))\n  filter_text=[]\n  for token in tokenized_text:\n    if token not in stop_words:\n          filter_text.append(token)\n\n  #POS and lemmatize\n  lemmatizer = WordNetLemmatizer()\n  lemmatizeResults=[lemmatizer.lemmatize(token,getWordnetPos(token)) for token in filter_text]\n  return ' '.join(lemmatizeResults)\n\ndef pdftotext(m,preprocessing=False):\n  #Open pdf file\n  doc=fitz.open(m)\n\n  #Convert pdf to text\n  text=''\n  for page in doc:\n    text+=page.get_text()\n\n  #Remove new line\n  text=' '.join(text.split('\\n'))\n\n  if preprocessing:\n    return cv_preprocessing(text)\n  else:\n    return text","metadata":{"id":"r9nqqCF5kaLs","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:55:00.453108Z","iopub.execute_input":"2025-05-07T00:55:00.453947Z","iopub.status.idle":"2025-05-07T00:55:00.462206Z","shell.execute_reply.started":"2025-05-07T00:55:00.453914Z","shell.execute_reply":"2025-05-07T00:55:00.461452Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"def bert_predict(cv_data: str):\n    # Token id embedding, mask word embedding\n    tokenized_texts = []\n    temp_token = []\n\n    # Add [CLS] at the front\n    temp_token.append('[CLS]')\n    token_list = tokenizer.tokenize(cv_data)\n    for token in token_list:\n        temp_token.append(token)\n\n    # Trim the token to fit the length requirement\n    if len(temp_token) > MAX_LEN - 1:\n        temp_token = temp_token[:MAX_LEN - 1]\n\n    # Add [SEP] at the end\n    temp_token.append('[SEP]')\n    tokenized_texts.append(temp_token)\n\n    # Make id embedding  \n    input_ids = pad_sequences([tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n                              maxlen=MAX_LEN, dtype='long', truncating='post', padding='post')\n    attention_masks = [[float(i > 0) for i in ii] for ii in input_ids]\n    segment_ids = [[0] * len(input_id) for input_id in input_ids]\n\n    # Make embeddings into torch tensor\n    input_ids = torch.tensor(input_ids)\n    attention_masks = torch.tensor(attention_masks)\n    segment_ids = torch.tensor(segment_ids)\n\n    with torch.no_grad():\n        outputs = bert_model(input_ids.cuda(), token_type_ids=None, attention_mask=None)\n        logits = outputs[0]\n\n    predict_results = logits.detach().cpu().numpy()\n    results_arrays_soft = softmax(predict_results, axis=-1)\n    result_array = results_arrays_soft\n    result_list = np.argmax(result_array, axis=-1)[0]  # <-- FIX: take first element to get flat array\n\n    # Get token predict tag\n    for i, mark in enumerate(attention_masks[0]):\n        if mark > 0:\n            predicted_index = int(result_list[i])  # <-- FIX: ensure it's an int\n            print(f'{temp_token[i]:50} {idx2tag[predicted_index]}')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:55:06.941019Z","iopub.execute_input":"2025-05-07T00:55:06.941838Z","iopub.status.idle":"2025-05-07T00:55:06.952034Z","shell.execute_reply.started":"2025-05-07T00:55:06.941806Z","shell.execute_reply":"2025-05-07T00:55:06.951178Z"}},"outputs":[],"execution_count":62},{"cell_type":"markdown","source":"# Test with one train data","metadata":{"id":"C8-hhrt2AjCX"}},{"cell_type":"code","source":"import torch\nimport numpy as np\nfrom pytorch_pretrained_bert import BertTokenizer, BertForTokenClassification\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Define device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n# Load tokenizer\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n\n# Define tags for BILUO scheme\nlabels = ['NAME', 'CLG', 'DEG', 'GRADYEAR', 'YOE', 'COMPANY', 'DESIG', 'SKILLS', 'LOC', 'EMAIL']\ntags = ['O'] + [f\"{prefix}-{label}\" for label in labels for prefix in ['B', 'I', 'L', 'U']] + ['[CLS]', '[SEP]', 'X']\ntag2idx = {tag: idx for idx, tag in enumerate(tags)}\nidx2tag = {idx: tag for tag, idx in tag2idx.items()}\n\n# Load and move model to device\nbert_model = BertForTokenClassification.from_pretrained('bert-base-uncased', num_labels=len(tag2idx))\nbert_model = bert_model.to(device)\n\ndef bert_predict(text):\n    # Tokenize input text\n    tokenized_texts = []\n    tokens = [\"[CLS]\"] + tokenizer.tokenize(text)[:510] + [\"[SEP]\"]\n    tokenized_texts.append(tokens)\n\n    # Convert tokens to input IDs\n    input_ids = pad_sequences(\n        [tokenizer.convert_tokens_to_ids(txt) for txt in tokenized_texts],\n        maxlen=512,\n        dtype=\"long\",\n        truncating=\"post\",\n        padding=\"post\"\n    )\n\n    # Create attention mask\n    attention_masks = [[float(i > 0) for i in ii] for ii in input_ids]\n\n    # Convert to PyTorch tensors and move to device\n    input_ids = torch.tensor(input_ids).to(device)\n    attention_masks = torch.tensor(attention_masks).to(device)\n\n    # Model in evaluation mode\n    bert_model.eval()\n\n    # Forward pass\n    with torch.no_grad():\n        logits = bert_model(input_ids=input_ids, attention_mask=attention_masks)\n        logits = logits.detach().cpu().numpy()\n\n    # Get predicted indices\n    predicted_indices = np.argmax(logits, axis=2)[0]  # Take first batch (batch_size=1)\n\n    # Align predictions with tokens\n    result = []\n    for i, mask in enumerate(attention_masks[0]):\n        if mask > 0:  # Only consider non-padded tokens\n            predicted_tag = idx2tag[predicted_indices[i]]\n            result.append((tokens[i], predicted_tag))\n\n    return result\n\n# Test the function (assuming df is your DataFrame)\nimport pandas as pd\n# Example: df = pd.read_json('/content/drive/MyDrive/Colab Notebooks/NLP/BERT/data/Resumes.json', lines=True)\nresult = bert_predict(df.iloc[0]['content'])\nfor token, tag in result:\n    print(f\"{token:<50} {tag}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:58:03.504802Z","iopub.execute_input":"2025-05-07T00:58:03.505098Z","iopub.status.idle":"2025-05-07T00:58:09.907795Z","shell.execute_reply.started":"2025-05-07T00:58:03.505075Z","shell.execute_reply":"2025-05-07T00:58:09.906923Z"}},"outputs":[{"name":"stdout","text":"[CLS]                                              [CLS]\nab                                                 U-CLG\n##his                                              U-CLG\n##he                                               U-CLG\n##k                                                I-LOC\nj                                                  U-DESIG\n##ha                                               L-LOC\napplication                                        B-CLG\ndevelopment                                        U-DESIG\nassociate                                          I-EMAIL\n-                                                  U-DESIG\naccent                                             L-GRADYEAR\n##ure                                              B-CLG\nbengal                                             L-GRADYEAR\n##uru                                              L-EMAIL\n,                                                  U-CLG\nkarnataka                                          B-EMAIL\n-                                                  U-DESIG\nemail                                              I-EMAIL\nme                                                 I-EMAIL\non                                                 I-EMAIL\nindeed                                             I-EMAIL\n:                                                  U-DESIG\nindeed                                             U-CLG\n.                                                  U-CLG\ncom                                                I-EMAIL\n/                                                  I-EMAIL\nr                                                  B-NAME\n/                                                  U-DESIG\nab                                                 B-YOE\n##his                                              U-CLG\n##he                                               L-EMAIL\n##k                                                I-YOE\n-                                                  U-DESIG\nj                                                  U-YOE\n##ha                                               L-LOC\n/                                                  U-DESIG\n10                                                 L-EMAIL\n##e                                                L-EMAIL\n##7                                                U-EMAIL\n##a                                                U-EMAIL\n##8                                                I-NAME\n##cb                                               U-EMAIL\n##7                                                I-NAME\n##32                                               I-NAME\n##bc                                               I-NAME\n##43                                               I-COMPANY\n##a                                                U-EMAIL\n•                                                  O\nto                                                 I-LOC\nwork                                               B-GRADYEAR\nfor                                                L-CLG\nan                                                 L-CLG\norganization                                       O\nwhich                                              B-GRADYEAR\nprovides                                           L-SKILLS\nme                                                 I-LOC\nthe                                                I-LOC\nopportunity                                        L-COMPANY\nto                                                 I-LOC\nimprove                                            I-YOE\nmy                                                 I-CLG\nskills                                             L-SKILLS\nand                                                B-DEG\nknowledge                                          I-CLG\nfor                                                U-DESIG\nmy                                                 B-EMAIL\nindividual                                         B-EMAIL\nand                                                I-LOC\ncompany                                            B-EMAIL\n'                                                  U-DESIG\ns                                                  I-LOC\ngrowth                                             I-LOC\nin                                                 L-CLG\nbest                                               U-DESIG\npossible                                           I-LOC\nways                                               I-LOC\n.                                                  U-EMAIL\nwilling                                            I-LOC\nto                                                 I-LOC\nrelocate                                           U-EMAIL\nto                                                 I-LOC\n:                                                  U-DESIG\nbangalore                                          U-EMAIL\n,                                                  U-CLG\nkarnataka                                          B-EMAIL\nwork                                               I-CLG\nexperience                                         I-LOC\napplication                                        I-SKILLS\ndevelopment                                        U-DESIG\nassociate                                          I-EMAIL\naccent                                             U-CLG\n##ure                                              U-EMAIL\n-                                                  I-LOC\nnovember                                           U-EMAIL\n2017                                               U-YOE\nto                                                 I-LOC\npresent                                            B-NAME\nrole                                               U-EMAIL\n:                                                  U-DESIG\ncurrently                                          I-LOC\nworking                                            B-EMAIL\non                                                 I-COMPANY\nchat                                               I-CLG\n-                                                  I-CLG\nbot                                                I-CLG\n.                                                  B-EMAIL\ndeveloping                                         L-DEG\nback                                               I-EMAIL\n##end                                              I-LOC\noracle                                             U-DESIG\npeoples                                            I-LOC\n##oft                                              L-COMPANY\nque                                                B-DEG\n##ries                                             L-COMPANY\nfor                                                L-COMPANY\nthe                                                L-CLG\nbot                                                I-DEG\nwhich                                              L-CLG\nwill                                               U-EMAIL\nbe                                                 U-EMAIL\ntriggered                                          U-EMAIL\nbased                                              U-DESIG\non                                                 U-DESIG\ngiven                                              U-EMAIL\ninput                                              U-EMAIL\n.                                                  U-DESIG\nalso                                               U-DESIG\n,                                                  U-EMAIL\ntraining                                           L-SKILLS\nthe                                                U-CLG\nbot                                                I-EMAIL\nfor                                                B-DEG\ndifferent                                          I-LOC\npossible                                           I-LOC\nutter                                              I-LOC\n##ances                                            L-COMPANY\n(                                                  U-CLG\nboth                                               B-LOC\npositive                                           B-DEG\nand                                                U-EMAIL\nnegative                                           B-DEG\n)                                                  B-CLG\n,                                                  L-CLG\nwhich                                              B-YOE\nwill                                               U-DESIG\nbe                                                 U-EMAIL\ngiven                                              B-YOE\nas                                                 L-CLG\ninput                                              L-CLG\nby                                                 I-LOC\nthe                                                I-LOC\nuser                                               U-CLG\n.                                                  B-CLG\neducation                                          L-SKILLS\nb                                                  O\n.                                                  B-YOE\ne                                                  L-EMAIL\nin                                                 B-SKILLS\ninformation                                        B-CLG\nscience                                            B-SKILLS\nand                                                B-YOE\nengineering                                        B-SKILLS\nb                                                  I-CLG\n.                                                  B-CLG\nv                                                  I-LOC\n.                                                  B-CLG\nb                                                  I-LOC\ncollege                                            B-SKILLS\nof                                                 B-DEG\nengineering                                        B-SKILLS\nand                                                B-YOE\ntechnology                                         L-CLG\n-                                                  U-DESIG\nhub                                                U-DESIG\n##li                                               U-EMAIL\n,                                                  U-CLG\nkarnataka                                          B-EMAIL\naugust                                             L-CLG\n2013                                               U-YOE\nto                                                 I-LOC\njune                                               L-CLG\n2017                                               U-YOE\n12th                                               L-EMAIL\nin                                                 B-SKILLS\nmathematics                                        B-SKILLS\nwood                                               L-EMAIL\n##bine                                             L-EMAIL\nmodern                                             L-COMPANY\nschool                                             U-DESIG\napril                                              B-CLG\n2011                                               U-DESIG\nto                                                 I-LOC\nmarch                                              L-CLG\n2013                                               L-COMPANY\n10th                                               L-SKILLS\nken                                                I-LOC\n##dr                                               U-DEG\n##iya                                              B-DEG\nvi                                                 U-DESIG\n##dya                                              U-DESIG\n##laya                                             U-DESIG\napril                                              L-GRADYEAR\n2001                                               B-DEG\nto                                                 I-LOC\nmarch                                              L-CLG\n2011                                               B-NAME\nskills                                             L-SKILLS\nc                                                  L-EMAIL\n(                                                  B-SKILLS\nless                                               B-DEG\nthan                                               L-LOC\n1                                                  I-YOE\nyear                                               I-CLG\n)                                                  B-GRADYEAR\n,                                                  B-DEG\ndatabase                                           L-EMAIL\n(                                                  L-CLG\nless                                               I-DESIG\nthan                                               L-LOC\n1                                                  L-NAME\nyear                                               I-CLG\n)                                                  L-DEG\n,                                                  B-DEG\ndatabase                                           I-YOE\nmanagement                                         U-NAME\n(                                                  L-CLG\nless                                               I-DESIG\nthan                                               U-EMAIL\n1                                                  I-YOE\nyear                                               I-CLG\n)                                                  L-CLG\n,                                                  U-DESIG\ndatabase                                           L-EMAIL\nmanagement                                         I-DESIG\nsystem                                             I-CLG\n(                                                  L-CLG\nless                                               I-DESIG\nthan                                               U-EMAIL\n1                                                  I-YOE\nyear                                               I-CLG\n)                                                  L-CLG\n,                                                  L-CLG\njava                                               U-NAME\n(                                                  L-CLG\nless                                               I-DESIG\nthan                                               U-EMAIL\n1                                                  I-YOE\nyear                                               I-CLG\n)                                                  B-GRADYEAR\nadditional                                         I-EMAIL\ninformation                                        L-COMPANY\ntechnical                                          U-SKILLS\nskills                                             I-YOE\nhttps                                              L-SKILLS\n:                                                  B-GRADYEAR\n/                                                  O\n/                                                  U-DESIG\nwww                                                I-CLG\n.                                                  B-GRADYEAR\nindeed                                             I-EMAIL\n.                                                  U-DESIG\ncom                                                O\n/                                                  U-DESIG\nr                                                  U-DESIG\n/                                                  U-DESIG\nab                                                 B-YOE\n##his                                              L-GRADYEAR\n##he                                               I-YOE\n##k                                                I-YOE\n-                                                  U-DESIG\nj                                                  U-DESIG\n##ha                                               U-EMAIL\n/                                                  U-DESIG\n10                                                 L-EMAIL\n##e                                                I-YOE\n##7                                                U-EMAIL\n##a                                                U-EMAIL\n##8                                                U-EMAIL\n##cb                                               U-EMAIL\n##7                                                I-NAME\n##32                                               I-NAME\n##bc                                               I-NAME\n##43                                               L-CLG\n##a                                                U-EMAIL\n?                                                  I-DEG\nis                                                 U-EMAIL\n##id                                               U-EMAIL\n=                                                  I-CLG\nrex                                                B-LOC\n-                                                  U-DESIG\ndownload                                           B-LOC\n&                                                  I-EMAIL\nik                                                 U-EMAIL\n##w                                                B-NAME\n=                                                  I-CLG\ndownload                                           U-EMAIL\n-                                                  U-DESIG\ntop                                                U-GRADYEAR\n&                                                  L-CLG\nco                                                 U-EMAIL\n=                                                  I-CLG\nin                                                 L-DEG\n•                                                  U-GRADYEAR\nprogramming                                        L-SKILLS\nlanguage                                           I-CLG\n:                                                  U-DESIG\nc                                                  B-LOC\n,                                                  U-CLG\nc                                                  B-YOE\n+                                                  L-LOC\n+                                                  I-CLG\n,                                                  U-DESIG\njava                                               U-DESIG\n•                                                  U-NAME\noracle                                             U-DESIG\npeoples                                            L-DESIG\n##oft                                              I-LOC\n•                                                  U-NAME\ninternet                                           L-COMPANY\nof                                                 U-DEG\nthings                                             L-COMPANY\n•                                                  L-COMPANY\nmachine                                            I-YOE\nlearning                                           U-DESIG\n•                                                  U-NAME\ndatabase                                           L-EMAIL\nmanagement                                         B-DEG\nsystem                                             I-YOE\n•                                                  L-COMPANY\ncomputer                                           I-YOE\nnetworks                                           U-GRADYEAR\n•                                                  U-GRADYEAR\noperating                                          U-DESIG\nsystem                                             [CLS]\nworked                                             U-DESIG\non                                                 I-COMPANY\n:                                                  U-DESIG\nlinux                                              I-COMPANY\n,                                                  U-CLG\nwindows                                            U-GRADYEAR\n,                                                  U-DESIG\nmac                                                I-COMPANY\nnon                                                B-DEG\n-                                                  L-CLG\ntechnical                                          L-COMPANY\nskills                                             L-SKILLS\n•                                                  U-GRADYEAR\nhonest                                             B-DEG\nand                                                U-EMAIL\nhard                                               B-EMAIL\n-                                                  I-LOC\nworking                                            L-CLG\n•                                                  I-CLG\ntolerant                                           U-GRADYEAR\nand                                                U-EMAIL\nflexible                                           U-EMAIL\nto                                                 I-LOC\ndifferent                                          I-YOE\nsituations                                         I-LOC\n•                                                  U-GRADYEAR\npolite                                             U-EMAIL\nand                                                U-EMAIL\ncalm                                               U-EMAIL\n•                                                  U-GRADYEAR\nteam                                               I-YOE\n-                                                  I-LOC\nplayer                                             U-GRADYEAR\n[SEP]                                              B-EMAIL\n","output_type":"stream"}],"execution_count":65},{"cell_type":"code","source":"bert_predict(df.iloc[0]['content'])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lt0QDHiwARvN","executionInfo":{"status":"ok","timestamp":1683644048343,"user_tz":-480,"elapsed":2251,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"fc282953-a811-4e1e-a673-df6e7ee74502","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:59:10.266991Z","iopub.execute_input":"2025-05-07T00:59:10.267403Z","iopub.status.idle":"2025-05-07T00:59:10.349734Z","shell.execute_reply.started":"2025-05-07T00:59:10.267359Z","shell.execute_reply":"2025-05-07T00:59:10.349021Z"}},"outputs":[{"execution_count":66,"output_type":"execute_result","data":{"text/plain":"[('[CLS]', '[CLS]'),\n ('ab', 'U-CLG'),\n ('##his', 'U-CLG'),\n ('##he', 'U-CLG'),\n ('##k', 'I-LOC'),\n ('j', 'U-DESIG'),\n ('##ha', 'L-LOC'),\n ('application', 'B-CLG'),\n ('development', 'U-DESIG'),\n ('associate', 'I-EMAIL'),\n ('-', 'U-DESIG'),\n ('accent', 'L-GRADYEAR'),\n ('##ure', 'B-CLG'),\n ('bengal', 'L-GRADYEAR'),\n ('##uru', 'L-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('-', 'U-DESIG'),\n ('email', 'I-EMAIL'),\n ('me', 'I-EMAIL'),\n ('on', 'I-EMAIL'),\n ('indeed', 'I-EMAIL'),\n (':', 'U-DESIG'),\n ('indeed', 'U-CLG'),\n ('.', 'U-CLG'),\n ('com', 'I-EMAIL'),\n ('/', 'I-EMAIL'),\n ('r', 'B-NAME'),\n ('/', 'U-DESIG'),\n ('ab', 'B-YOE'),\n ('##his', 'U-CLG'),\n ('##he', 'L-EMAIL'),\n ('##k', 'I-YOE'),\n ('-', 'U-DESIG'),\n ('j', 'U-YOE'),\n ('##ha', 'L-LOC'),\n ('/', 'U-DESIG'),\n ('10', 'L-EMAIL'),\n ('##e', 'L-EMAIL'),\n ('##7', 'U-EMAIL'),\n ('##a', 'U-EMAIL'),\n ('##8', 'I-NAME'),\n ('##cb', 'U-EMAIL'),\n ('##7', 'I-NAME'),\n ('##32', 'I-NAME'),\n ('##bc', 'I-NAME'),\n ('##43', 'I-COMPANY'),\n ('##a', 'U-EMAIL'),\n ('•', 'O'),\n ('to', 'I-LOC'),\n ('work', 'B-GRADYEAR'),\n ('for', 'L-CLG'),\n ('an', 'L-CLG'),\n ('organization', 'O'),\n ('which', 'B-GRADYEAR'),\n ('provides', 'L-SKILLS'),\n ('me', 'I-LOC'),\n ('the', 'I-LOC'),\n ('opportunity', 'L-COMPANY'),\n ('to', 'I-LOC'),\n ('improve', 'I-YOE'),\n ('my', 'I-CLG'),\n ('skills', 'L-SKILLS'),\n ('and', 'B-DEG'),\n ('knowledge', 'I-CLG'),\n ('for', 'U-DESIG'),\n ('my', 'B-EMAIL'),\n ('individual', 'B-EMAIL'),\n ('and', 'I-LOC'),\n ('company', 'B-EMAIL'),\n (\"'\", 'U-DESIG'),\n ('s', 'I-LOC'),\n ('growth', 'I-LOC'),\n ('in', 'L-CLG'),\n ('best', 'U-DESIG'),\n ('possible', 'I-LOC'),\n ('ways', 'I-LOC'),\n ('.', 'U-EMAIL'),\n ('willing', 'I-LOC'),\n ('to', 'I-LOC'),\n ('relocate', 'U-EMAIL'),\n ('to', 'I-LOC'),\n (':', 'U-DESIG'),\n ('bangalore', 'U-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('work', 'I-CLG'),\n ('experience', 'I-LOC'),\n ('application', 'I-SKILLS'),\n ('development', 'U-DESIG'),\n ('associate', 'I-EMAIL'),\n ('accent', 'U-CLG'),\n ('##ure', 'U-EMAIL'),\n ('-', 'I-LOC'),\n ('november', 'U-EMAIL'),\n ('2017', 'U-YOE'),\n ('to', 'I-LOC'),\n ('present', 'B-NAME'),\n ('role', 'U-EMAIL'),\n (':', 'U-DESIG'),\n ('currently', 'I-LOC'),\n ('working', 'B-EMAIL'),\n ('on', 'I-COMPANY'),\n ('chat', 'I-CLG'),\n ('-', 'I-CLG'),\n ('bot', 'I-CLG'),\n ('.', 'B-EMAIL'),\n ('developing', 'L-DEG'),\n ('back', 'I-EMAIL'),\n ('##end', 'I-LOC'),\n ('oracle', 'U-DESIG'),\n ('peoples', 'I-LOC'),\n ('##oft', 'L-COMPANY'),\n ('que', 'B-DEG'),\n ('##ries', 'L-COMPANY'),\n ('for', 'L-COMPANY'),\n ('the', 'L-CLG'),\n ('bot', 'I-DEG'),\n ('which', 'L-CLG'),\n ('will', 'U-EMAIL'),\n ('be', 'U-EMAIL'),\n ('triggered', 'U-EMAIL'),\n ('based', 'U-DESIG'),\n ('on', 'U-DESIG'),\n ('given', 'U-EMAIL'),\n ('input', 'U-EMAIL'),\n ('.', 'U-DESIG'),\n ('also', 'U-DESIG'),\n (',', 'U-EMAIL'),\n ('training', 'L-SKILLS'),\n ('the', 'U-CLG'),\n ('bot', 'I-EMAIL'),\n ('for', 'B-DEG'),\n ('different', 'I-LOC'),\n ('possible', 'I-LOC'),\n ('utter', 'I-LOC'),\n ('##ances', 'L-COMPANY'),\n ('(', 'U-CLG'),\n ('both', 'B-LOC'),\n ('positive', 'B-DEG'),\n ('and', 'U-EMAIL'),\n ('negative', 'B-DEG'),\n (')', 'B-CLG'),\n (',', 'L-CLG'),\n ('which', 'B-YOE'),\n ('will', 'U-DESIG'),\n ('be', 'U-EMAIL'),\n ('given', 'B-YOE'),\n ('as', 'L-CLG'),\n ('input', 'L-CLG'),\n ('by', 'I-LOC'),\n ('the', 'I-LOC'),\n ('user', 'U-CLG'),\n ('.', 'B-CLG'),\n ('education', 'L-SKILLS'),\n ('b', 'O'),\n ('.', 'B-YOE'),\n ('e', 'L-EMAIL'),\n ('in', 'B-SKILLS'),\n ('information', 'B-CLG'),\n ('science', 'B-SKILLS'),\n ('and', 'B-YOE'),\n ('engineering', 'B-SKILLS'),\n ('b', 'I-CLG'),\n ('.', 'B-CLG'),\n ('v', 'I-LOC'),\n ('.', 'B-CLG'),\n ('b', 'I-LOC'),\n ('college', 'B-SKILLS'),\n ('of', 'B-DEG'),\n ('engineering', 'B-SKILLS'),\n ('and', 'B-YOE'),\n ('technology', 'L-CLG'),\n ('-', 'U-DESIG'),\n ('hub', 'U-DESIG'),\n ('##li', 'U-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('august', 'L-CLG'),\n ('2013', 'U-YOE'),\n ('to', 'I-LOC'),\n ('june', 'L-CLG'),\n ('2017', 'U-YOE'),\n ('12th', 'L-EMAIL'),\n ('in', 'B-SKILLS'),\n ('mathematics', 'B-SKILLS'),\n ('wood', 'L-EMAIL'),\n ('##bine', 'L-EMAIL'),\n ('modern', 'L-COMPANY'),\n ('school', 'U-DESIG'),\n ('april', 'B-CLG'),\n ('2011', 'U-DESIG'),\n ('to', 'I-LOC'),\n ('march', 'L-CLG'),\n ('2013', 'L-COMPANY'),\n ('10th', 'L-SKILLS'),\n ('ken', 'I-LOC'),\n ('##dr', 'U-DEG'),\n ('##iya', 'B-DEG'),\n ('vi', 'U-DESIG'),\n ('##dya', 'U-DESIG'),\n ('##laya', 'U-DESIG'),\n ('april', 'L-GRADYEAR'),\n ('2001', 'B-DEG'),\n ('to', 'I-LOC'),\n ('march', 'L-CLG'),\n ('2011', 'B-NAME'),\n ('skills', 'L-SKILLS'),\n ('c', 'L-EMAIL'),\n ('(', 'B-SKILLS'),\n ('less', 'B-DEG'),\n ('than', 'L-LOC'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'B-GRADYEAR'),\n (',', 'B-DEG'),\n ('database', 'L-EMAIL'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'L-LOC'),\n ('1', 'L-NAME'),\n ('year', 'I-CLG'),\n (')', 'L-DEG'),\n (',', 'B-DEG'),\n ('database', 'I-YOE'),\n ('management', 'U-NAME'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'L-CLG'),\n (',', 'U-DESIG'),\n ('database', 'L-EMAIL'),\n ('management', 'I-DESIG'),\n ('system', 'I-CLG'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'L-CLG'),\n (',', 'L-CLG'),\n ('java', 'U-NAME'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'B-GRADYEAR'),\n ('additional', 'I-EMAIL'),\n ('information', 'L-COMPANY'),\n ('technical', 'U-SKILLS'),\n ('skills', 'I-YOE'),\n ('https', 'L-SKILLS'),\n (':', 'B-GRADYEAR'),\n ('/', 'O'),\n ('/', 'U-DESIG'),\n ('www', 'I-CLG'),\n ('.', 'B-GRADYEAR'),\n ('indeed', 'I-EMAIL'),\n ('.', 'U-DESIG'),\n ('com', 'O'),\n ('/', 'U-DESIG'),\n ('r', 'U-DESIG'),\n ('/', 'U-DESIG'),\n ('ab', 'B-YOE'),\n ('##his', 'L-GRADYEAR'),\n ('##he', 'I-YOE'),\n ('##k', 'I-YOE'),\n ('-', 'U-DESIG'),\n ('j', 'U-DESIG'),\n ('##ha', 'U-EMAIL'),\n ('/', 'U-DESIG'),\n ('10', 'L-EMAIL'),\n ('##e', 'I-YOE'),\n ('##7', 'U-EMAIL'),\n ('##a', 'U-EMAIL'),\n ('##8', 'U-EMAIL'),\n ('##cb', 'U-EMAIL'),\n ('##7', 'I-NAME'),\n ('##32', 'I-NAME'),\n ('##bc', 'I-NAME'),\n ('##43', 'L-CLG'),\n ('##a', 'U-EMAIL'),\n ('?', 'I-DEG'),\n ('is', 'U-EMAIL'),\n ('##id', 'U-EMAIL'),\n ('=', 'I-CLG'),\n ('rex', 'B-LOC'),\n ('-', 'U-DESIG'),\n ('download', 'B-LOC'),\n ('&', 'I-EMAIL'),\n ('ik', 'U-EMAIL'),\n ('##w', 'B-NAME'),\n ('=', 'I-CLG'),\n ('download', 'U-EMAIL'),\n ('-', 'U-DESIG'),\n ('top', 'U-GRADYEAR'),\n ('&', 'L-CLG'),\n ('co', 'U-EMAIL'),\n ('=', 'I-CLG'),\n ('in', 'L-DEG'),\n ('•', 'U-GRADYEAR'),\n ('programming', 'L-SKILLS'),\n ('language', 'I-CLG'),\n (':', 'U-DESIG'),\n ('c', 'B-LOC'),\n (',', 'U-CLG'),\n ('c', 'B-YOE'),\n ('+', 'L-LOC'),\n ('+', 'I-CLG'),\n (',', 'U-DESIG'),\n ('java', 'U-DESIG'),\n ('•', 'U-NAME'),\n ('oracle', 'U-DESIG'),\n ('peoples', 'L-DESIG'),\n ('##oft', 'I-LOC'),\n ('•', 'U-NAME'),\n ('internet', 'L-COMPANY'),\n ('of', 'U-DEG'),\n ('things', 'L-COMPANY'),\n ('•', 'L-COMPANY'),\n ('machine', 'I-YOE'),\n ('learning', 'U-DESIG'),\n ('•', 'U-NAME'),\n ('database', 'L-EMAIL'),\n ('management', 'B-DEG'),\n ('system', 'I-YOE'),\n ('•', 'L-COMPANY'),\n ('computer', 'I-YOE'),\n ('networks', 'U-GRADYEAR'),\n ('•', 'U-GRADYEAR'),\n ('operating', 'U-DESIG'),\n ('system', '[CLS]'),\n ('worked', 'U-DESIG'),\n ('on', 'I-COMPANY'),\n (':', 'U-DESIG'),\n ('linux', 'I-COMPANY'),\n (',', 'U-CLG'),\n ('windows', 'U-GRADYEAR'),\n (',', 'U-DESIG'),\n ('mac', 'I-COMPANY'),\n ('non', 'B-DEG'),\n ('-', 'L-CLG'),\n ('technical', 'L-COMPANY'),\n ('skills', 'L-SKILLS'),\n ('•', 'U-GRADYEAR'),\n ('honest', 'B-DEG'),\n ('and', 'U-EMAIL'),\n ('hard', 'B-EMAIL'),\n ('-', 'I-LOC'),\n ('working', 'L-CLG'),\n ('•', 'I-CLG'),\n ('tolerant', 'U-GRADYEAR'),\n ('and', 'U-EMAIL'),\n ('flexible', 'U-EMAIL'),\n ('to', 'I-LOC'),\n ('different', 'I-YOE'),\n ('situations', 'I-LOC'),\n ('•', 'U-GRADYEAR'),\n ('polite', 'U-EMAIL'),\n ('and', 'U-EMAIL'),\n ('calm', 'U-EMAIL'),\n ('•', 'U-GRADYEAR'),\n ('team', 'I-YOE'),\n ('-', 'I-LOC'),\n ('player', 'U-GRADYEAR'),\n ('[SEP]', 'B-EMAIL')]"},"metadata":{}}],"execution_count":66},{"cell_type":"code","source":"bert_predict(data[0][0])","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1-dC6ODN_miW","executionInfo":{"status":"ok","timestamp":1683644017630,"user_tz":-480,"elapsed":7,"user":{"displayName":"Wong Yun Jet","userId":"09982030126116333359"}},"outputId":"a4827264-747b-4a54-e75a-0b2bc87a2f40","trusted":true,"execution":{"iopub.status.busy":"2025-05-07T00:59:17.011500Z","iopub.execute_input":"2025-05-07T00:59:17.011786Z","iopub.status.idle":"2025-05-07T00:59:17.094154Z","shell.execute_reply.started":"2025-05-07T00:59:17.011765Z","shell.execute_reply":"2025-05-07T00:59:17.093498Z"}},"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"[('[CLS]', '[CLS]'),\n ('ab', 'U-CLG'),\n ('##his', 'U-CLG'),\n ('##he', 'U-CLG'),\n ('##k', 'I-LOC'),\n ('j', 'U-DESIG'),\n ('##ha', 'L-LOC'),\n ('application', 'B-CLG'),\n ('development', 'U-DESIG'),\n ('associate', 'I-EMAIL'),\n ('-', 'U-DESIG'),\n ('accent', 'L-GRADYEAR'),\n ('##ure', 'B-CLG'),\n ('bengal', 'L-GRADYEAR'),\n ('##uru', 'L-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('-', 'U-DESIG'),\n ('email', 'I-EMAIL'),\n ('me', 'I-EMAIL'),\n ('on', 'I-EMAIL'),\n ('indeed', 'I-EMAIL'),\n (':', 'U-DESIG'),\n ('indeed', 'U-CLG'),\n ('.', 'U-CLG'),\n ('com', 'I-EMAIL'),\n ('/', 'I-EMAIL'),\n ('r', 'B-NAME'),\n ('/', 'U-DESIG'),\n ('ab', 'B-YOE'),\n ('##his', 'U-CLG'),\n ('##he', 'L-EMAIL'),\n ('##k', 'I-YOE'),\n ('-', 'U-DESIG'),\n ('j', 'U-YOE'),\n ('##ha', 'L-LOC'),\n ('/', 'U-DESIG'),\n ('10', 'L-EMAIL'),\n ('##e', 'L-EMAIL'),\n ('##7', 'U-EMAIL'),\n ('##a', 'U-EMAIL'),\n ('##8', 'I-NAME'),\n ('##cb', 'U-EMAIL'),\n ('##7', 'I-NAME'),\n ('##32', 'I-NAME'),\n ('##bc', 'I-NAME'),\n ('##43', 'I-COMPANY'),\n ('##a', 'U-EMAIL'),\n ('•', 'O'),\n ('to', 'I-LOC'),\n ('work', 'B-GRADYEAR'),\n ('for', 'L-CLG'),\n ('an', 'L-CLG'),\n ('organization', 'O'),\n ('which', 'B-GRADYEAR'),\n ('provides', 'L-SKILLS'),\n ('me', 'I-LOC'),\n ('the', 'I-LOC'),\n ('opportunity', 'L-COMPANY'),\n ('to', 'I-LOC'),\n ('improve', 'I-YOE'),\n ('my', 'I-CLG'),\n ('skills', 'L-SKILLS'),\n ('and', 'B-DEG'),\n ('knowledge', 'I-CLG'),\n ('for', 'U-DESIG'),\n ('my', 'B-EMAIL'),\n ('individual', 'B-EMAIL'),\n ('and', 'I-LOC'),\n ('company', 'B-EMAIL'),\n (\"'\", 'U-DESIG'),\n ('s', 'I-LOC'),\n ('growth', 'I-LOC'),\n ('in', 'L-CLG'),\n ('best', 'U-DESIG'),\n ('possible', 'I-LOC'),\n ('ways', 'I-LOC'),\n ('.', 'U-EMAIL'),\n ('willing', 'I-LOC'),\n ('to', 'I-LOC'),\n ('relocate', 'U-EMAIL'),\n ('to', 'I-LOC'),\n (':', 'U-DESIG'),\n ('bangalore', 'U-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('work', 'I-CLG'),\n ('experience', 'I-LOC'),\n ('application', 'I-SKILLS'),\n ('development', 'U-DESIG'),\n ('associate', 'I-EMAIL'),\n ('accent', 'U-CLG'),\n ('##ure', 'U-EMAIL'),\n ('-', 'I-LOC'),\n ('november', 'U-EMAIL'),\n ('2017', 'U-YOE'),\n ('to', 'I-LOC'),\n ('present', 'B-NAME'),\n ('role', 'U-EMAIL'),\n (':', 'U-DESIG'),\n ('currently', 'I-LOC'),\n ('working', 'B-EMAIL'),\n ('on', 'I-COMPANY'),\n ('chat', 'I-CLG'),\n ('-', 'I-CLG'),\n ('bot', 'I-CLG'),\n ('.', 'B-EMAIL'),\n ('developing', 'L-DEG'),\n ('back', 'I-EMAIL'),\n ('##end', 'I-LOC'),\n ('oracle', 'U-DESIG'),\n ('peoples', 'I-LOC'),\n ('##oft', 'L-COMPANY'),\n ('que', 'B-DEG'),\n ('##ries', 'L-COMPANY'),\n ('for', 'L-COMPANY'),\n ('the', 'L-CLG'),\n ('bot', 'I-DEG'),\n ('which', 'L-CLG'),\n ('will', 'U-EMAIL'),\n ('be', 'U-EMAIL'),\n ('triggered', 'U-EMAIL'),\n ('based', 'U-DESIG'),\n ('on', 'U-DESIG'),\n ('given', 'U-EMAIL'),\n ('input', 'U-EMAIL'),\n ('.', 'U-DESIG'),\n ('also', 'U-DESIG'),\n (',', 'U-EMAIL'),\n ('training', 'L-SKILLS'),\n ('the', 'U-CLG'),\n ('bot', 'I-EMAIL'),\n ('for', 'B-DEG'),\n ('different', 'I-LOC'),\n ('possible', 'I-LOC'),\n ('utter', 'I-LOC'),\n ('##ances', 'L-COMPANY'),\n ('(', 'U-CLG'),\n ('both', 'B-LOC'),\n ('positive', 'B-DEG'),\n ('and', 'U-EMAIL'),\n ('negative', 'B-DEG'),\n (')', 'B-CLG'),\n (',', 'L-CLG'),\n ('which', 'B-YOE'),\n ('will', 'U-DESIG'),\n ('be', 'U-EMAIL'),\n ('given', 'B-YOE'),\n ('as', 'L-CLG'),\n ('input', 'L-CLG'),\n ('by', 'I-LOC'),\n ('the', 'I-LOC'),\n ('user', 'U-CLG'),\n ('.', 'B-CLG'),\n ('education', 'L-SKILLS'),\n ('b', 'O'),\n ('.', 'B-YOE'),\n ('e', 'L-EMAIL'),\n ('in', 'B-SKILLS'),\n ('information', 'B-CLG'),\n ('science', 'B-SKILLS'),\n ('and', 'B-YOE'),\n ('engineering', 'B-SKILLS'),\n ('b', 'I-CLG'),\n ('.', 'B-CLG'),\n ('v', 'I-LOC'),\n ('.', 'B-CLG'),\n ('b', 'I-LOC'),\n ('college', 'B-SKILLS'),\n ('of', 'B-DEG'),\n ('engineering', 'B-SKILLS'),\n ('and', 'B-YOE'),\n ('technology', 'L-CLG'),\n ('-', 'U-DESIG'),\n ('hub', 'U-DESIG'),\n ('##li', 'U-EMAIL'),\n (',', 'U-CLG'),\n ('karnataka', 'B-EMAIL'),\n ('august', 'L-CLG'),\n ('2013', 'U-YOE'),\n ('to', 'I-LOC'),\n ('june', 'L-CLG'),\n ('2017', 'U-YOE'),\n ('12th', 'L-EMAIL'),\n ('in', 'B-SKILLS'),\n ('mathematics', 'B-SKILLS'),\n ('wood', 'L-EMAIL'),\n ('##bine', 'L-EMAIL'),\n ('modern', 'L-COMPANY'),\n ('school', 'U-DESIG'),\n ('april', 'B-CLG'),\n ('2011', 'U-DESIG'),\n ('to', 'I-LOC'),\n ('march', 'L-CLG'),\n ('2013', 'L-COMPANY'),\n ('10th', 'L-SKILLS'),\n ('ken', 'I-LOC'),\n ('##dr', 'U-DEG'),\n ('##iya', 'B-DEG'),\n ('vi', 'U-DESIG'),\n ('##dya', 'U-DESIG'),\n ('##laya', 'U-DESIG'),\n ('april', 'L-GRADYEAR'),\n ('2001', 'B-DEG'),\n ('to', 'I-LOC'),\n ('march', 'L-CLG'),\n ('2011', 'B-NAME'),\n ('skills', 'L-SKILLS'),\n ('c', 'L-EMAIL'),\n ('(', 'B-SKILLS'),\n ('less', 'B-DEG'),\n ('than', 'L-LOC'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'B-GRADYEAR'),\n (',', 'B-DEG'),\n ('database', 'L-EMAIL'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'L-LOC'),\n ('1', 'L-NAME'),\n ('year', 'I-CLG'),\n (')', 'L-DEG'),\n (',', 'B-DEG'),\n ('database', 'I-YOE'),\n ('management', 'U-NAME'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'L-CLG'),\n (',', 'U-DESIG'),\n ('database', 'L-EMAIL'),\n ('management', 'I-DESIG'),\n ('system', 'I-CLG'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'L-CLG'),\n (',', 'L-CLG'),\n ('java', 'U-NAME'),\n ('(', 'L-CLG'),\n ('less', 'I-DESIG'),\n ('than', 'U-EMAIL'),\n ('1', 'I-YOE'),\n ('year', 'I-CLG'),\n (')', 'B-GRADYEAR'),\n ('additional', 'I-EMAIL'),\n ('information', 'L-COMPANY'),\n ('technical', 'U-SKILLS'),\n ('skills', 'I-YOE'),\n ('https', 'L-SKILLS'),\n (':', 'B-GRADYEAR'),\n ('/', 'O'),\n ('/', 'U-DESIG'),\n ('www', 'I-CLG'),\n ('.', 'B-GRADYEAR'),\n ('indeed', 'I-EMAIL'),\n ('.', 'U-DESIG'),\n ('com', 'O'),\n ('/', 'U-DESIG'),\n ('r', 'U-DESIG'),\n ('/', 'U-DESIG'),\n ('ab', 'B-YOE'),\n ('##his', 'L-GRADYEAR'),\n ('##he', 'I-YOE'),\n ('##k', 'I-YOE'),\n ('-', 'U-DESIG'),\n ('j', 'U-DESIG'),\n ('##ha', 'U-EMAIL'),\n ('/', 'U-DESIG'),\n ('10', 'L-EMAIL'),\n ('##e', 'I-YOE'),\n ('##7', 'U-EMAIL'),\n ('##a', 'U-EMAIL'),\n ('##8', 'U-EMAIL'),\n ('##cb', 'U-EMAIL'),\n ('##7', 'I-NAME'),\n ('##32', 'I-NAME'),\n ('##bc', 'I-NAME'),\n ('##43', 'L-CLG'),\n ('##a', 'U-EMAIL'),\n ('?', 'I-DEG'),\n ('is', 'U-EMAIL'),\n ('##id', 'U-EMAIL'),\n ('=', 'I-CLG'),\n ('rex', 'B-LOC'),\n ('-', 'U-DESIG'),\n ('download', 'B-LOC'),\n ('&', 'I-EMAIL'),\n ('ik', 'U-EMAIL'),\n ('##w', 'B-NAME'),\n ('=', 'I-CLG'),\n ('download', 'U-EMAIL'),\n ('-', 'U-DESIG'),\n ('top', 'U-GRADYEAR'),\n ('&', 'L-CLG'),\n ('co', 'U-EMAIL'),\n ('=', 'I-CLG'),\n ('in', 'L-DEG'),\n ('•', 'U-GRADYEAR'),\n ('programming', 'L-SKILLS'),\n ('language', 'I-CLG'),\n (':', 'U-DESIG'),\n ('c', 'B-LOC'),\n (',', 'U-CLG'),\n ('c', 'B-YOE'),\n ('+', 'L-LOC'),\n ('+', 'I-CLG'),\n (',', 'U-DESIG'),\n ('java', 'U-DESIG'),\n ('•', 'U-NAME'),\n ('oracle', 'U-DESIG'),\n ('peoples', 'L-DESIG'),\n ('##oft', 'I-LOC'),\n ('•', 'U-NAME'),\n ('internet', 'L-COMPANY'),\n ('of', 'U-DEG'),\n ('things', 'L-COMPANY'),\n ('•', 'L-COMPANY'),\n ('machine', 'I-YOE'),\n ('learning', 'U-DESIG'),\n ('•', 'U-NAME'),\n ('database', 'L-EMAIL'),\n ('management', 'B-DEG'),\n ('system', 'I-YOE'),\n ('•', 'L-COMPANY'),\n ('computer', 'I-YOE'),\n ('networks', 'U-GRADYEAR'),\n ('•', 'U-GRADYEAR'),\n ('operating', 'U-DESIG'),\n ('system', '[CLS]'),\n ('worked', 'U-DESIG'),\n ('on', 'I-COMPANY'),\n (':', 'U-DESIG'),\n ('linux', 'I-COMPANY'),\n (',', 'U-CLG'),\n ('windows', 'U-GRADYEAR'),\n (',', 'U-DESIG'),\n ('mac', 'I-COMPANY'),\n ('non', 'B-DEG'),\n ('-', 'L-CLG'),\n ('technical', 'L-COMPANY'),\n ('skills', 'L-SKILLS'),\n ('•', 'U-GRADYEAR'),\n ('honest', 'B-DEG'),\n ('and', 'U-EMAIL'),\n ('hard', 'B-EMAIL'),\n ('-', 'I-LOC'),\n ('working', 'L-CLG'),\n ('•', 'I-CLG'),\n ('tolerant', 'U-GRADYEAR'),\n ('and', 'U-EMAIL'),\n ('flexible', 'U-EMAIL'),\n ('to', 'I-LOC'),\n ('different', 'I-YOE'),\n ('situations', 'I-LOC'),\n ('•', 'U-GRADYEAR'),\n ('polite', 'U-EMAIL'),\n ('and', 'U-EMAIL'),\n ('calm', 'U-EMAIL'),\n ('•', 'U-GRADYEAR'),\n ('team', 'I-YOE'),\n ('-', 'I-LOC'),\n ('player', 'U-GRADYEAR'),\n ('[SEP]', 'B-EMAIL')]"},"metadata":{}}],"execution_count":67},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n# Assuming `data` is a list of (tokens, labels) tuples\ntrain_data, test_data = train_test_split(data, test_size=0.2, random_state=42)\n\nprint(f\"Training set size: {len(train_data)}\")\nprint(f\"Test set size: {len(test_data)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T01:16:01.042332Z","iopub.execute_input":"2025-05-07T01:16:01.042876Z","iopub.status.idle":"2025-05-07T01:16:01.048863Z","shell.execute_reply.started":"2025-05-07T01:16:01.042854Z","shell.execute_reply":"2025-05-07T01:16:01.047986Z"}},"outputs":[{"name":"stdout","text":"Training set size: 176\nTest set size: 44\n","output_type":"stream"}],"execution_count":68},{"cell_type":"code","source":"import pandas as pd\n\ndf = pd.read_json('/kaggle/input/bertdata/data/Resumes.json', lines=True)\nprint(\"Columns in DataFrame:\", df.columns)\nprint(\"Sample row:\", df.iloc[0].to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:37:39.570030Z","iopub.execute_input":"2025-05-07T02:37:39.570592Z","iopub.status.idle":"2025-05-07T02:37:39.598022Z","shell.execute_reply.started":"2025-05-07T02:37:39.570567Z","shell.execute_reply":"2025-05-07T02:37:39.597318Z"}},"outputs":[{"name":"stdout","text":"Columns in DataFrame: Index(['content', 'annotation', 'extras'], dtype='object')\nSample row: {'content': \"Abhishek Jha\\nApplication Development Associate - Accenture\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n\\n• To work for an organization which provides me the opportunity to improve my skills\\nand knowledge for my individual and company's growth in best possible ways.\\n\\nWilling to relocate to: Bangalore, Karnataka\\n\\nWORK EXPERIENCE\\n\\nApplication Development Associate\\n\\nAccenture -\\n\\nNovember 2017 to Present\\n\\nRole: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries\\nfor the Bot which will be triggered based on given input. Also, Training the bot for different possible\\nutterances (Both positive and negative), which will be given as\\ninput by the user.\\n\\nEDUCATION\\n\\nB.E in Information science and engineering\\n\\nB.v.b college of engineering and technology -  Hubli, Karnataka\\n\\nAugust 2013 to June 2017\\n\\n12th in Mathematics\\n\\nWoodbine modern school\\n\\nApril 2011 to March 2013\\n\\n10th\\n\\nKendriya Vidyalaya\\n\\nApril 2001 to March 2011\\n\\nSKILLS\\n\\nC (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Skills\\n\\nhttps://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player\", 'annotation': [{'label': ['Skills'], 'points': [{'start': 1295, 'end': 1621, 'text': '\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player'}]}, {'label': ['Skills'], 'points': [{'start': 993, 'end': 1153, 'text': 'C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)'}]}, {'label': ['College Name'], 'points': [{'start': 939, 'end': 956, 'text': 'Kendriya Vidyalaya'}]}, {'label': ['College Name'], 'points': [{'start': 883, 'end': 904, 'text': 'Woodbine modern school'}]}, {'label': ['Graduation Year'], 'points': [{'start': 856, 'end': 860, 'text': '2017\\n'}]}, {'label': ['College Name'], 'points': [{'start': 771, 'end': 813, 'text': 'B.v.b college of engineering and technology'}]}, {'label': ['Designation'], 'points': [{'start': 727, 'end': 769, 'text': 'B.E in Information science and engineering\\n'}]}, {'label': ['Companies worked at'], 'points': [{'start': 407, 'end': 415, 'text': 'Accenture'}]}, {'label': ['Designation'], 'points': [{'start': 372, 'end': 404, 'text': 'Application Development Associate'}]}, {'label': ['Email Address'], 'points': [{'start': 95, 'end': 145, 'text': 'Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n'}]}, {'label': ['Location'], 'points': [{'start': 60, 'end': 68, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 49, 'end': 57, 'text': 'Accenture'}]}, {'label': ['Designation'], 'points': [{'start': 13, 'end': 45, 'text': 'Application Development Associate'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Abhishek Jha'}]}], 'extras': nan}\n","output_type":"stream"}],"execution_count":100},{"cell_type":"code","source":"import spacy\nfrom spacy.training import offsets_to_biluo_tags\n\nnlp = spacy.load('en_core_web_lg')\n\ndef get_train_data(df):\n    sentences = []\n    tags = []\n    entity_dict = {\n        'Name': 'NAME',\n        'College Name': 'CLG',\n        'Degree': 'DEG',\n        'Graduation Year': 'GRADYEAR',\n        'Years of Experience': 'YOE',\n        'Companies worked at': 'COMPANY',\n        'Designation': 'DESIG',\n        'Skills': 'SKILLS',\n        'Location': 'LOC',\n        'Email Address': 'EMAIL'\n    }\n    \n    for i in range(len(df)):\n        text = df['content'][i]\n        annotations = df['annotation'][i] if 'annotation' in df.columns else []\n        \n        # Convert Dataturks annotations to entity spans\n        entities = []\n        if annotations:\n            for ann in annotations:\n                if isinstance(ann, dict) and 'points' in ann and 'label' in ann:\n                    label = ann['label'][0] if ann['label'] else None\n                    if label in entity_dict:\n                        for point in ann['points']:\n                            start = point['start']\n                            end = point['end']\n                            entities.append((start, end, entity_dict[label]))\n        \n        # Generate BILUO tags\n        doc = nlp(text)\n        try:\n            biluo_tags = offsets_to_biluo_tags(doc, entities)\n            sentences.append([token.text for token in doc])\n            tags.append(biluo_tags)\n        except ValueError as e:\n            print(f\"Skipping row {i} due to error: {e}\")\n            continue\n    \n    return sentences, tags","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:38:00.849610Z","iopub.execute_input":"2025-05-07T02:38:00.850169Z","iopub.status.idle":"2025-05-07T02:38:02.417464Z","shell.execute_reply.started":"2025-05-07T02:38:00.850147Z","shell.execute_reply":"2025-05-07T02:38:02.416861Z"}},"outputs":[],"execution_count":101},{"cell_type":"code","source":"df = pd.read_json('/kaggle/input/bertdata/data/Resumes.json', lines=True)\nsentences, tags = get_train_data(df)\ntag_vals = set(['X', '[CLS]', '[SEP]'])\nfor tag_list in tags:\n    tag_vals.update(tag_list)\nprint(\"Training tags:\", tag_vals)\nprint(\"Number of training tags:\", len(tag_vals))\n\ntag2idx = {t: i for i, t in enumerate(tag_vals)}\nidx2tag = {i: t for t, i in tag2idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:38:12.614920Z","iopub.execute_input":"2025-05-07T02:38:12.615220Z","iopub.status.idle":"2025-05-07T02:38:34.849854Z","shell.execute_reply.started":"2025-05-07T02:38:12.615201Z","shell.execute_reply":"2025-05-07T02:38:34.848610Z"}},"outputs":[{"name":"stdout","text":"Skipping row 6 due to error: [E103] Trying to set conflicting doc.ents: '(38, 57, 'COMPANY')' and '(38, 43, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 15 due to error: [E103] Trying to set conflicting doc.ents: '(1803, 1820, 'SKILLS')' and '(1803, 1808, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 18 due to error: [E103] Trying to set conflicting doc.ents: '(707, 711, 'LOC')' and '(677, 718, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 20 due to error: [E103] Trying to set conflicting doc.ents: '(1417, 1422, 'COMPANY')' and '(1356, 1792, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 28 due to error: [E103] Trying to set conflicting doc.ents: '(34, 49, 'COMPANY')' and '(34, 48, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 31 due to error: [E103] Trying to set conflicting doc.ents: '(4186, 4190, 'COMPANY')' and '(4121, 4398, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 32 due to error: [E103] Trying to set conflicting doc.ents: '(2128, 2143, 'COMPANY')' and '(2116, 2142, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 33 due to error: [E103] Trying to set conflicting doc.ents: '(1844, 1872, 'SKILLS')' and '(1844, 1859, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 41 due to error: [E103] Trying to set conflicting doc.ents: '(3535, 3540, 'COMPANY')' and '(3466, 3818, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 43 due to error: [E103] Trying to set conflicting doc.ents: '(6861, 6869, 'COMPANY')' and '(6305, 7257, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 52 due to error: [E103] Trying to set conflicting doc.ents: '(819, 834, 'DESIG')' and '(812, 834, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 54 due to error: [E103] Trying to set conflicting doc.ents: '(13883, 13886, 'SKILLS')' and '(13883, 13885, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 55 due to error: [E103] Trying to set conflicting doc.ents: '(3385, 3390, 'COMPANY')' and '(3345, 3895, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 56 due to error: [E103] Trying to set conflicting doc.ents: '(2886, 2888, 'COMPANY')' and '(2861, 3073, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 60 due to error: [E103] Trying to set conflicting doc.ents: '(1180, 1200, 'DESIG')' and '(1173, 1199, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 61 due to error: [E103] Trying to set conflicting doc.ents: '(47, 56, 'COMPANY')' and '(47, 56, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 64 due to error: [E103] Trying to set conflicting doc.ents: '(4231, 4237, 'COMPANY')' and '(4213, 4348, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 68 due to error: [E103] Trying to set conflicting doc.ents: '(370, 391, 'DESIG')' and '(370, 390, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 69 due to error: [E103] Trying to set conflicting doc.ents: '(2528, 2539, 'CLG')' and '(2528, 2531, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 76 due to error: [E103] Trying to set conflicting doc.ents: '(6682, 6686, 'COMPANY')' and '(6646, 7278, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 80 due to error: [E103] Trying to set conflicting doc.ents: '(463, 487, 'COMPANY')' and '(463, 468, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 81 due to error: [E103] Trying to set conflicting doc.ents: '(4374, 4397, 'COMPANY')' and '(4374, 4379, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 84 due to error: [E103] Trying to set conflicting doc.ents: '(941, 946, 'COMPANY')' and '(415, 1909, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 85 due to error: [E103] Trying to set conflicting doc.ents: '(3939, 3947, 'COMPANY')' and '(3912, 4039, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 87 due to error: [E103] Trying to set conflicting doc.ents: '(2076, 2078, 'SKILLS')' and '(2058, 2090, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 88 due to error: [E103] Trying to set conflicting doc.ents: '(1342, 1347, 'COMPANY')' and '(1311, 1762, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 92 due to error: [E103] Trying to set conflicting doc.ents: '(4774, 4777, 'LOC')' and '(4744, 4788, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 93 due to error: [E103] Trying to set conflicting doc.ents: '(3461, 3464, 'GRADYEAR')' and '(1416, 3889, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 95 due to error: [E103] Trying to set conflicting doc.ents: '(15, 49, 'DESIG')' and '(15, 48, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 100 due to error: [E103] Trying to set conflicting doc.ents: '(7777, 7783, 'YOE')' and '(7745, 7836, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 105 due to error: [E103] Trying to set conflicting doc.ents: '(10, 32, 'DESIG')' and '(9, 31, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 114 due to error: [E103] Trying to set conflicting doc.ents: '(4708, 4716, 'COMPANY')' and '(4681, 4716, 'DEG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 120 due to error: [E103] Trying to set conflicting doc.ents: '(1576, 1579, 'LOC')' and '(1563, 1607, 'EMAIL')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 128 due to error: [E103] Trying to set conflicting doc.ents: '(729, 774, 'CLG')' and '(729, 734, 'LOC')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 129 due to error: [E103] Trying to set conflicting doc.ents: '(497, 540, 'SKILLS')' and '(497, 506, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 133 due to error: [E103] Trying to set conflicting doc.ents: '(295, 320, 'CLG')' and '(295, 304, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 135 due to error: [E103] Trying to set conflicting doc.ents: '(458, 500, 'SKILLS')' and '(458, 466, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 140 due to error: [E103] Trying to set conflicting doc.ents: '(1514, 1522, 'COMPANY')' and '(1502, 1599, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 146 due to error: [E103] Trying to set conflicting doc.ents: '(381, 390, 'COMPANY')' and '(367, 518, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 148 due to error: [E103] Trying to set conflicting doc.ents: '(983, 991, 'COMPANY')' and '(970, 1001, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 151 due to error: [E103] Trying to set conflicting doc.ents: '(1476, 1500, 'DESIG')' and '(1476, 1484, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 152 due to error: [E103] Trying to set conflicting doc.ents: '(2733, 2741, 'COMPANY')' and '(2537, 2755, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 154 due to error: [E103] Trying to set conflicting doc.ents: '(8133, 8135, 'DEG')' and '(8133, 8135, 'DEG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 166 due to error: [E103] Trying to set conflicting doc.ents: '(2907, 2937, 'DESIG')' and '(2907, 2936, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 181 due to error: [E103] Trying to set conflicting doc.ents: '(1105, 1112, 'COMPANY')' and '(1080, 1120, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 185 due to error: [E103] Trying to set conflicting doc.ents: '(3981, 3989, 'LOC')' and '(3973, 3989, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 204 due to error: [E103] Trying to set conflicting doc.ents: '(1258, 1272, 'COMPANY')' and '(1258, 1261, 'LOC')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 206 due to error: [E103] Trying to set conflicting doc.ents: '(549, 581, 'DESIG')' and '(539, 580, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 218 due to error: [E103] Trying to set conflicting doc.ents: '(52, 54, 'DESIG')' and '(22, 55, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nTraining tags: {'U-LOC', 'B-EMAIL', 'I-CLG', 'I-DEG', 'X', 'B-LOC', 'I-LOC', 'B-COMPANY', 'O', 'U-GRADYEAR', 'L-DESIG', 'U-SKILLS', 'B-CLG', 'L-CLG', 'I-COMPANY', '-', 'I-EMAIL', 'U-COMPANY', '[CLS]', 'L-SKILLS', 'B-DEG', '[SEP]', 'I-SKILLS', 'B-DESIG', 'L-DEG', 'B-YOE', 'U-EMAIL', 'L-LOC', 'I-YOE', 'U-YOE', 'L-YOE', 'L-COMPANY', 'U-DEG', 'U-DESIG', 'U-CLG', 'B-SKILLS', 'L-EMAIL', 'I-DESIG'}\nNumber of training tags: 38\n","output_type":"stream"}],"execution_count":102},{"cell_type":"code","source":"labels = ['NAME', 'CLG', 'DEG', 'GRADYEAR', 'YOE', 'COMPANY', 'DESIG', 'SKILLS', 'LOC', 'EMAIL']\ntags = ['O'] + [f\"{prefix}-{label}\" for label in labels for prefix in ['B', 'I', 'L', 'U'] if not (prefix == 'I' and label == 'CLG')] + ['[CLS]', '[SEP]', 'X']\ntag2idx = {tag: idx for idx, tag in enumerate(tags)}\nidx2tag = {idx: tag for tag, idx in tag2idx.items()}\nprint(\"Number of tags:\", len(tag2idx))  # Should be 43","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:39:56.328390Z","iopub.execute_input":"2025-05-07T02:39:56.328674Z","iopub.status.idle":"2025-05-07T02:39:56.335021Z","shell.execute_reply.started":"2025-05-07T02:39:56.328653Z","shell.execute_reply":"2025-05-07T02:39:56.334298Z"}},"outputs":[{"name":"stdout","text":"Number of tags: 43\n","output_type":"stream"}],"execution_count":104},{"cell_type":"code","source":"from pytorch_pretrained_bert import BertTokenizer, BertForTokenClassification\nimport torch\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\nbert_model = BertForTokenClassification.from_pretrained('/kaggle/working/bert_model/', num_labels=len(tag2idx))\nbert_model = bert_model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:40:05.636716Z","iopub.execute_input":"2025-05-07T02:40:05.636963Z","iopub.status.idle":"2025-05-07T02:40:07.859855Z","shell.execute_reply.started":"2025-05-07T02:40:05.636947Z","shell.execute_reply":"2025-05-07T02:40:07.859263Z"}},"outputs":[],"execution_count":105},{"cell_type":"code","source":"import pandas as pd\nimport spacy\nfrom spacy.training import offsets_to_biluo_tags\n\nnlp = spacy.load('en_core_web_lg')\n\ndef get_train_data(df):\n    sentences = []\n    tags = []\n    entity_dict = {\n        'Name': 'NAME',\n        'College Name': 'CLG',\n        'Degree': 'DEG',\n        'Graduation Year': 'GRADYEAR',\n        'Years of Experience': 'YOE',\n        'Companies worked at': 'COMPANY',\n        'Designation': 'DESIG',\n        'Skills': 'SKILLS',\n        'Location': 'LOC',\n        'Email Address': 'EMAIL'\n    }\n    \n    for i in range(len(df)):\n        text = df['content'][i]\n        annotations = df['annotation'][i] if 'annotation' in df.columns else []\n        \n        entities = []\n        if annotations:\n            for ann in annotations:\n                if isinstance(ann, dict) and 'points' in ann and 'label' in ann:\n                    label = ann['label'][0] if ann['label'] else None\n                    if label in entity_dict:\n                        for point in ann['points']:\n                            start = point['start']\n                            end = point['end']\n                            entities.append((start, end, entity_dict[label]))\n        \n        doc = nlp(text)\n        try:\n            biluo_tags = offsets_to_biluo_tags(doc, entities)\n            sentences.append([token.text for token in doc])\n            tags.append(biluo_tags)\n        except ValueError as e:\n            print(f\"Skipping row {i} due to error: {e}\")\n            continue\n    \n    return sentences, tags\n\ndf = pd.read_json('/kaggle/input/bertdata/data/Resumes.json', lines=True)\nsentences, tags = get_train_data(df)\ntag_vals = set(['X', '[CLS]', '[SEP]'])\nfor tag_list in tags:\n    tag_vals.update(tag_list)\nprint(\"Training tags:\", tag_vals)\nprint(\"Number of training tags:\", len(tag_vals))\n\ntag2idx = {t: i for i, t in enumerate(tag_vals)}\nidx2tag = {i: t for t, i in tag2idx.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:40:18.683548Z","iopub.execute_input":"2025-05-07T02:40:18.683826Z","iopub.status.idle":"2025-05-07T02:40:42.432704Z","shell.execute_reply.started":"2025-05-07T02:40:18.683804Z","shell.execute_reply":"2025-05-07T02:40:42.432015Z"}},"outputs":[{"name":"stdout","text":"Skipping row 6 due to error: [E103] Trying to set conflicting doc.ents: '(38, 57, 'COMPANY')' and '(38, 43, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 15 due to error: [E103] Trying to set conflicting doc.ents: '(1803, 1820, 'SKILLS')' and '(1803, 1808, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 18 due to error: [E103] Trying to set conflicting doc.ents: '(707, 711, 'LOC')' and '(677, 718, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 20 due to error: [E103] Trying to set conflicting doc.ents: '(1417, 1422, 'COMPANY')' and '(1356, 1792, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 28 due to error: [E103] Trying to set conflicting doc.ents: '(34, 49, 'COMPANY')' and '(34, 48, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 31 due to error: [E103] Trying to set conflicting doc.ents: '(4186, 4190, 'COMPANY')' and '(4121, 4398, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 32 due to error: [E103] Trying to set conflicting doc.ents: '(2128, 2143, 'COMPANY')' and '(2116, 2142, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 33 due to error: [E103] Trying to set conflicting doc.ents: '(1844, 1872, 'SKILLS')' and '(1844, 1859, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 41 due to error: [E103] Trying to set conflicting doc.ents: '(3535, 3540, 'COMPANY')' and '(3466, 3818, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 43 due to error: [E103] Trying to set conflicting doc.ents: '(6861, 6869, 'COMPANY')' and '(6305, 7257, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 52 due to error: [E103] Trying to set conflicting doc.ents: '(819, 834, 'DESIG')' and '(812, 834, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 54 due to error: [E103] Trying to set conflicting doc.ents: '(13883, 13886, 'SKILLS')' and '(13883, 13885, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 55 due to error: [E103] Trying to set conflicting doc.ents: '(3385, 3390, 'COMPANY')' and '(3345, 3895, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 56 due to error: [E103] Trying to set conflicting doc.ents: '(2886, 2888, 'COMPANY')' and '(2861, 3073, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 60 due to error: [E103] Trying to set conflicting doc.ents: '(1180, 1200, 'DESIG')' and '(1173, 1199, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 61 due to error: [E103] Trying to set conflicting doc.ents: '(47, 56, 'COMPANY')' and '(47, 56, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 64 due to error: [E103] Trying to set conflicting doc.ents: '(4231, 4237, 'COMPANY')' and '(4213, 4348, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 68 due to error: [E103] Trying to set conflicting doc.ents: '(370, 391, 'DESIG')' and '(370, 390, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 69 due to error: [E103] Trying to set conflicting doc.ents: '(2528, 2539, 'CLG')' and '(2528, 2531, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 76 due to error: [E103] Trying to set conflicting doc.ents: '(6682, 6686, 'COMPANY')' and '(6646, 7278, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 80 due to error: [E103] Trying to set conflicting doc.ents: '(463, 487, 'COMPANY')' and '(463, 468, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 81 due to error: [E103] Trying to set conflicting doc.ents: '(4374, 4397, 'COMPANY')' and '(4374, 4379, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 84 due to error: [E103] Trying to set conflicting doc.ents: '(941, 946, 'COMPANY')' and '(415, 1909, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 85 due to error: [E103] Trying to set conflicting doc.ents: '(3939, 3947, 'COMPANY')' and '(3912, 4039, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 87 due to error: [E103] Trying to set conflicting doc.ents: '(2076, 2078, 'SKILLS')' and '(2058, 2090, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 88 due to error: [E103] Trying to set conflicting doc.ents: '(1342, 1347, 'COMPANY')' and '(1311, 1762, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 92 due to error: [E103] Trying to set conflicting doc.ents: '(4774, 4777, 'LOC')' and '(4744, 4788, 'CLG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 93 due to error: [E103] Trying to set conflicting doc.ents: '(3461, 3464, 'GRADYEAR')' and '(1416, 3889, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 95 due to error: [E103] Trying to set conflicting doc.ents: '(15, 49, 'DESIG')' and '(15, 48, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 100 due to error: [E103] Trying to set conflicting doc.ents: '(7777, 7783, 'YOE')' and '(7745, 7836, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 105 due to error: [E103] Trying to set conflicting doc.ents: '(10, 32, 'DESIG')' and '(9, 31, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 114 due to error: [E103] Trying to set conflicting doc.ents: '(4708, 4716, 'COMPANY')' and '(4681, 4716, 'DEG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 120 due to error: [E103] Trying to set conflicting doc.ents: '(1576, 1579, 'LOC')' and '(1563, 1607, 'EMAIL')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 128 due to error: [E103] Trying to set conflicting doc.ents: '(729, 774, 'CLG')' and '(729, 734, 'LOC')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 129 due to error: [E103] Trying to set conflicting doc.ents: '(497, 540, 'SKILLS')' and '(497, 506, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 133 due to error: [E103] Trying to set conflicting doc.ents: '(295, 320, 'CLG')' and '(295, 304, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 135 due to error: [E103] Trying to set conflicting doc.ents: '(458, 500, 'SKILLS')' and '(458, 466, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 140 due to error: [E103] Trying to set conflicting doc.ents: '(1514, 1522, 'COMPANY')' and '(1502, 1599, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 146 due to error: [E103] Trying to set conflicting doc.ents: '(381, 390, 'COMPANY')' and '(367, 518, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 148 due to error: [E103] Trying to set conflicting doc.ents: '(983, 991, 'COMPANY')' and '(970, 1001, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 151 due to error: [E103] Trying to set conflicting doc.ents: '(1476, 1500, 'DESIG')' and '(1476, 1484, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 152 due to error: [E103] Trying to set conflicting doc.ents: '(2733, 2741, 'COMPANY')' and '(2537, 2755, 'SKILLS')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 154 due to error: [E103] Trying to set conflicting doc.ents: '(8133, 8135, 'DEG')' and '(8133, 8135, 'DEG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 166 due to error: [E103] Trying to set conflicting doc.ents: '(2907, 2937, 'DESIG')' and '(2907, 2936, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 181 due to error: [E103] Trying to set conflicting doc.ents: '(1105, 1112, 'COMPANY')' and '(1080, 1120, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 185 due to error: [E103] Trying to set conflicting doc.ents: '(3981, 3989, 'LOC')' and '(3973, 3989, 'COMPANY')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 204 due to error: [E103] Trying to set conflicting doc.ents: '(1258, 1272, 'COMPANY')' and '(1258, 1261, 'LOC')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 206 due to error: [E103] Trying to set conflicting doc.ents: '(549, 581, 'DESIG')' and '(539, 580, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nSkipping row 218 due to error: [E103] Trying to set conflicting doc.ents: '(52, 54, 'DESIG')' and '(22, 55, 'DESIG')'. A token can only be part of one entity, so make sure the entities you're setting don't overlap. To work with overlapping entities, consider using doc.spans instead.\nTraining tags: {'U-LOC', 'B-EMAIL', 'I-CLG', 'I-DEG', 'X', 'B-LOC', 'I-LOC', 'B-COMPANY', 'O', 'U-GRADYEAR', 'L-DESIG', 'U-SKILLS', 'B-CLG', 'L-CLG', 'I-COMPANY', '-', 'I-EMAIL', 'U-COMPANY', '[CLS]', 'L-SKILLS', 'B-DEG', '[SEP]', 'I-SKILLS', 'B-DESIG', 'L-DEG', 'B-YOE', 'U-EMAIL', 'L-LOC', 'I-YOE', 'U-YOE', 'L-YOE', 'L-COMPANY', 'U-DEG', 'U-DESIG', 'U-CLG', 'B-SKILLS', 'L-EMAIL', 'I-DESIG'}\nNumber of training tags: 38\n","output_type":"stream"}],"execution_count":106},{"cell_type":"code","source":"print(\"Columns in DataFrame:\", df.columns)\nprint(\"Sample row:\", df.iloc[0].to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:40:46.189754Z","iopub.execute_input":"2025-05-07T02:40:46.190401Z","iopub.status.idle":"2025-05-07T02:40:46.195528Z","shell.execute_reply.started":"2025-05-07T02:40:46.190372Z","shell.execute_reply":"2025-05-07T02:40:46.194660Z"}},"outputs":[{"name":"stdout","text":"Columns in DataFrame: Index(['content', 'annotation', 'extras'], dtype='object')\nSample row: {'content': \"Abhishek Jha\\nApplication Development Associate - Accenture\\n\\nBengaluru, Karnataka - Email me on Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n\\n• To work for an organization which provides me the opportunity to improve my skills\\nand knowledge for my individual and company's growth in best possible ways.\\n\\nWilling to relocate to: Bangalore, Karnataka\\n\\nWORK EXPERIENCE\\n\\nApplication Development Associate\\n\\nAccenture -\\n\\nNovember 2017 to Present\\n\\nRole: Currently working on Chat-bot. Developing Backend Oracle PeopleSoft Queries\\nfor the Bot which will be triggered based on given input. Also, Training the bot for different possible\\nutterances (Both positive and negative), which will be given as\\ninput by the user.\\n\\nEDUCATION\\n\\nB.E in Information science and engineering\\n\\nB.v.b college of engineering and technology -  Hubli, Karnataka\\n\\nAugust 2013 to June 2017\\n\\n12th in Mathematics\\n\\nWoodbine modern school\\n\\nApril 2011 to March 2013\\n\\n10th\\n\\nKendriya Vidyalaya\\n\\nApril 2001 to March 2011\\n\\nSKILLS\\n\\nC (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTechnical Skills\\n\\nhttps://www.indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a?isid=rex-download&ikw=download-top&co=IN\\n\\n\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player\", 'annotation': [{'label': ['Skills'], 'points': [{'start': 1295, 'end': 1621, 'text': '\\n• Programming language: C, C++, Java\\n• Oracle PeopleSoft\\n• Internet Of Things\\n• Machine Learning\\n• Database Management System\\n• Computer Networks\\n• Operating System worked on: Linux, Windows, Mac\\n\\nNon - Technical Skills\\n\\n• Honest and Hard-Working\\n• Tolerant and Flexible to Different Situations\\n• Polite and Calm\\n• Team-Player'}]}, {'label': ['Skills'], 'points': [{'start': 993, 'end': 1153, 'text': 'C (Less than 1 year), Database (Less than 1 year), Database Management (Less than 1 year),\\nDatabase Management System (Less than 1 year), Java (Less than 1 year)'}]}, {'label': ['College Name'], 'points': [{'start': 939, 'end': 956, 'text': 'Kendriya Vidyalaya'}]}, {'label': ['College Name'], 'points': [{'start': 883, 'end': 904, 'text': 'Woodbine modern school'}]}, {'label': ['Graduation Year'], 'points': [{'start': 856, 'end': 860, 'text': '2017\\n'}]}, {'label': ['College Name'], 'points': [{'start': 771, 'end': 813, 'text': 'B.v.b college of engineering and technology'}]}, {'label': ['Designation'], 'points': [{'start': 727, 'end': 769, 'text': 'B.E in Information science and engineering\\n'}]}, {'label': ['Companies worked at'], 'points': [{'start': 407, 'end': 415, 'text': 'Accenture'}]}, {'label': ['Designation'], 'points': [{'start': 372, 'end': 404, 'text': 'Application Development Associate'}]}, {'label': ['Email Address'], 'points': [{'start': 95, 'end': 145, 'text': 'Indeed: indeed.com/r/Abhishek-Jha/10e7a8cb732bc43a\\n'}]}, {'label': ['Location'], 'points': [{'start': 60, 'end': 68, 'text': 'Bengaluru'}]}, {'label': ['Companies worked at'], 'points': [{'start': 49, 'end': 57, 'text': 'Accenture'}]}, {'label': ['Designation'], 'points': [{'start': 13, 'end': 45, 'text': 'Application Development Associate'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 11, 'text': 'Abhishek Jha'}]}], 'extras': nan}\n","output_type":"stream"}],"execution_count":107},{"cell_type":"code","source":"expected_tags = set(['O'] + [f\"{prefix}-{label}\" for label in ['NAME', 'CLG', 'DEG', 'GRADYEAR', 'YOE', 'COMPANY', 'DESIG', 'SKILLS', 'LOC', 'EMAIL'] for prefix in ['B', 'I', 'L', 'U']] + ['[CLS]', '[SEP]', 'X'])\nmissing_tag = expected_tags - tag_vals\nprint(\"Missing tag:\", missing_tag)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-07T02:40:57.717404Z","iopub.execute_input":"2025-05-07T02:40:57.717716Z","iopub.status.idle":"2025-05-07T02:40:57.722671Z","shell.execute_reply.started":"2025-05-07T02:40:57.717688Z","shell.execute_reply":"2025-05-07T02:40:57.721923Z"}},"outputs":[{"name":"stdout","text":"Missing tag: {'B-NAME', 'I-NAME', 'U-NAME', 'I-GRADYEAR', 'B-GRADYEAR', 'L-NAME', 'L-GRADYEAR'}\n","output_type":"stream"}],"execution_count":108}]}